{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johyunkang/adp_certificate/blob/main/models_pros_cons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3187ec49",
      "metadata": {
        "id": "3187ec49"
      },
      "source": [
        "# 모델별 특징과 장단점"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "768740a8",
      "metadata": {
        "id": "768740a8"
      },
      "source": [
        "## 1. 분류 (Classification)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e8922fcb",
      "metadata": {
        "id": "e8922fcb"
      },
      "source": [
        "1. 로지스틱 회귀\n",
        "    - 로지스틱 회귀는 기계 학습에서 일반적으로 사용되는 인기 있는 선형 분류 알고리즘입니다. 중소 규모의 데이터 세트에서 잘 작동하는 간단하고 이해하기 쉬운 알고리즘입니다.\n",
        "\n",
        "- 특징\n",
        "    - 결정 경계가 선형 함수일 때 잘 작동하는 선형 알고리즘.\n",
        "    - 클래스 확률로 해석할 수 있는 확률 출력을 제공합니다.\n",
        "    - 과적합을 방지하기 위해 정규화할 수 있습니다.\n",
        "- 장점:\n",
        "    - 간단하고 구현하기 쉽습니다.\n",
        "    - 중소 규모의 데이터 세트에서 잘 작동합니다.\n",
        "    - 해석 가능한 결과를 제공합니다.\n",
        "- 약점:\n",
        "    - 결정 경계가 비선형인 경우 제대로 작동하지 않을 수 있습니다.\n",
        "    - 관련 없는 특성이 많을 때 과적합이 발생할 수 있습니다.\n",
        "    \n",
        "2. 랜덤 포레스트\n",
        "- 랜덤 포레스트는 결정 트리를 기반으로 하는 인기 있는 앙상블 분류 알고리즘입니다. 광범위한 데이터 세트에서 잘 작동하는 유연한 알고리즘입니다.\n",
        "- 특징:\n",
        "    - 여러 결정 트리를 결합하는 앙상블 알고리즘.\n",
        "    - 비선형 결정 경계를 처리할 수 있습니다.\n",
        "    - 관련 없는 기능이 많은 데이터 세트를 처리할 수 있습니다.\n",
        "- 장점:\n",
        "    - 유연하고 광범위한 데이터 세트에서 잘 작동할 수 있습니다.\n",
        "    - 범주형 및 연속형 기능을 모두 처리할 수 있습니다.\n",
        "    - 기능 중요도 추정치를 제공합니다.\n",
        "- 약점:\n",
        "    - 대규모 데이터 세트에서 교육하는 데 속도가 느릴 수 있습니다.\n",
        "    - 상관관계가 높은 기능이 있는 데이터 세트에서는 제대로 작동하지 않을 수 있습니다.\n",
        "3. 서포트 벡터 머신(SVM)\n",
        "- SVM(Support Vector Machines)은 분류 및 회귀 분석에 널리 사용되는 알고리즘입니다. 광범위한 데이터 세트에서 잘 작동하는 강력한 알고리즘입니다.\n",
        "- 특징:\n",
        "    - 클래스를 최대로 분리하는 초평면을 찾는 알고리즘.\n",
        "    - 커널 트릭을 사용하여 비선형 결정 경계를 처리할 수 있습니다.\n",
        "    - 많은 기능을 가진 데이터 세트를 처리할 수 있습니다.\n",
        "- 장점:\n",
        "    - 강력하고 다양한 데이터 세트에서 잘 작동할 수 있습니다.\n",
        "    - 선형 및 비선형 결정 경계를 모두 처리할 수 있습니다.\n",
        "    - 우수한 일반화 성능을 제공합니다.\n",
        "- 담점:\n",
        "    - 대규모 데이터 세트에서 교육하는 데 속도가 느릴 수 있습니다.\n",
        "    - 커널 기능 선택에 민감할 수 있습니다.\n",
        "    \n",
        "4. XGBoost:\n",
        "- 특징:\n",
        "    - 그래디언트 부스팅 알고리즘을 사용하여 결정 트리의 앙상블을 생성합니다.\n",
        "    - 누락된 데이터 및 비선형 관계를 처리할 수 있습니다.\n",
        "    - 과적합을 방지하기 위해 정규화를 허용합니다.\n",
        "- 장점:\n",
        "    - 광범위한 분류 작업에서 뛰어난 성능을 제공합니다.\n",
        "    - 높은 차원의 대규모 데이터 세트를 처리할 수 있습니다.\n",
        "    - 빠른 실행 속도를 제공합니다.\n",
        "- 단점:\n",
        "    - 하이퍼파라미터 선택에 민감할 수 있습니다.\n",
        "    - 적절하게 정규화되지 않으면 과대적합되기 쉽습니다.\n",
        "    - 최적의 결과를 얻으려면 신중한 기능 엔지니어링이 필요합니다.\n",
        "    \n",
        "5. LightGBM:\n",
        "- 특징:\n",
        "    - 그래디언트 부스팅 알고리즘을 사용하여 결정 트리의 앙상블을 생성합니다.\n",
        "    - 높은 차원의 대규모 데이터 세트를 처리할 수 있습니다.\n",
        "    - 훈련 속도를 높이기 위해 히스토그램 기반 접근 방식을 사용합니다.\n",
        "\n",
        "- 장점:\n",
        "    - 광범위한 분류 작업에서 뛰어난 성능을 제공합니다.\n",
        "    - 특히 대규모 데이터 세트에서 빠른 실행 속도를 제공합니다.\n",
        "    - 원-핫 인코딩 없이 범주형 기능을 처리할 수 있습니다.\n",
        "\n",
        "- 단점:\n",
        "    - 하이퍼파라미터 선택에 민감할 수 있습니다.\n",
        "    - 더 작은 데이터 세트에서는 XGBoost만큼 성능이 좋지 않을 수 있습니다.\n",
        "    - 최적의 결과를 얻으려면 신중한 기능 엔지니어링이 필요합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2908eed5",
      "metadata": {
        "id": "2908eed5"
      },
      "source": [
        "### XGBoost\n",
        "- 일반 매개변수\n",
        "    - booster: 사용할 부스터 유형(기본값='gbtree')\n",
        "    - silent: 학습 중 메시지 출력 여부(default=0)\n",
        "    - nthread: 병렬 처리에 사용할 스레드 수(기본값=-1, 사용 가능한 모든 코어 사용)\n",
        "- 부스터 매개변수의 몇 가지 예입니다.\n",
        "    - max_depth: 앙상블에서 각 트리의 최대 깊이(default=6)\n",
        "    - eta: 부스팅 과정의 학습률(default=0.3)\n",
        "    - subsample: 교육 인스턴스의 하위 샘플 비율(기본값=1)\n",
        "    - colsample_bytree: 각 트리를 구성할 때 컬럼의 부표본 비율(default=1)\n",
        "- 하이퍼 파라미터\n",
        "    - learning_rate: 최소 손실 함수를 향해 이동하면서 각 반복에서 단계 크기를 결정합니다.\n",
        "    - n_estimators: 앙상블의 트리 수입니다.\n",
        "    - min_child_weight: 자식에 필요한 인스턴스 가중치의 최소 합입니다.\n",
        "    - gamma: 트리의 리프 노드에서 추가 파티션을 만드는 데 필요한 최소 손실 감소."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60feba6d",
      "metadata": {
        "scrolled": true,
        "id": "60feba6d",
        "outputId": "360d7160-728d-48eb-9d1f-c8d9aa056304"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define XGBoost classifier\n",
        "xgb = XGBClassifier()\n",
        "\n",
        "# Define hyperparameters to search over\n",
        "param_grid = {\n",
        "    'learning_rate': [0.1, 0.3, 0.5],\n",
        "    'max_depth': [3, 5, 7],\n",
        "    'n_estimators': [50, 100, 200],\n",
        "    'gamma': [0, 0.1, 0.2],\n",
        "    'min_child_weight': [1, 3, 5]\n",
        "}\n",
        "\n",
        "# Perform grid search to find best hyperparameters\n",
        "grid_search = GridSearchCV(estimator=xgb, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best hyperparameters and train final model\n",
        "best_params = grid_search.best_params_\n",
        "xgb_best = XGBClassifier(**best_params)\n",
        "xgb_best.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = xgb_best.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f7530e84",
      "metadata": {
        "id": "f7530e84"
      },
      "source": [
        "### LightGBM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "72f8cba8",
      "metadata": {
        "id": "72f8cba8"
      },
      "source": [
        "- 핵심 매개변수의 몇 가지 예입니다.\n",
        "    - objective: 최적화할 목적 함수 유형(default='regression')\n",
        "    - metric: 사용할 평가 메트릭(default='rmse')\n",
        "    - num_threads: 병렬 처리에 사용할 스레드 수(기본값=0, 사용 가능한 모든 코어 사용)\n",
        "- 부스팅 매개변수의 몇 가지 예는 다음과 같습니다.\n",
        "    - num_leaves: 각 트리의 최대 리프 수(기본값=31)\n",
        "    - learning_rate: 부스팅 과정의 학습률(default=0.1)\n",
        "    - feature_fraction: 각 트리를 구성할 때 열의 하위 표본 비율(기본값=1)\n",
        "    - bagging_fraction: 교육 인스턴스의 하위 샘플 비율(기본값=1)\n",
        "- 하이퍼 파라미터\n",
        "    - learning_rate: 최소 손실 함수를 향해 이동하면서 각 반복에서 단계 크기를 결정합니다.\n",
        "    - num_iterations: 수행할 부스팅 반복 횟수.\n",
        "    - min_data_in_leaf: 리프에 필요한 학습 인스턴스의 최소 개수입니다.\n",
        "    - lambda_l1: 가중치에 대한 L1 정규화 용어입니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69edbdaa",
      "metadata": {
        "scrolled": false,
        "id": "69edbdaa"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# Load iris dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define LightGBM classifier\n",
        "lgbm = LGBMClassifier()\n",
        "\n",
        "# Define hyperparameters to search over\n",
        "param_dist = {\n",
        "    'learning_rate': np.linspace(0.05, 0.5, 10),\n",
        "    'num_leaves': np.arange(10, 50, 5),\n",
        "    'max_depth': np.arange(3, 10),\n",
        "    'min_data_in_leaf': np.arange(10, 50, 5),\n",
        "    'lambda_l1': [0, 1e-3, 1e-2, 1e-1]\n",
        "}\n",
        "\n",
        "# Perform randomized search to find best hyperparameters\n",
        "random_search = RandomizedSearchCV(estimator=lgbm, param_distributions=param_dist, cv=5, n_iter=50, n_jobs=-1)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Get best hyperparameters and train final model\n",
        "best_params = random_search.best_params_\n",
        "lgbm_best = LGBMClassifier(**best_params)\n",
        "lgbm_best.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on test set\n",
        "y_pred = lgbm_best.predict(X_test)\n",
        "\n",
        "# Calculate accuracy score\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "88608310",
      "metadata": {
        "id": "88608310"
      },
      "source": [
        "### KNN Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "034ed21e",
      "metadata": {
        "id": "034ed21e"
      },
      "source": [
        "1. 특징\n",
        " - KNN(K-Nearest Neighbors)은 분류 및 회귀 작업 모두에 사용할 수 있는 다목적 모델입니다. \n",
        " - 데이터 포인트가 명확한 선형 분리가 없고 결정 경계가 비선형인 상황에서 자주 사용됩니다.\n",
        "2. 특징:\n",
        " - KNN은 비모수적 모델입니다. 즉, 입력과 출력 사이의 관계에 대한 특정 기능적 형식을 가정하지 않습니다.\n",
        "- KNN은 게으른 학습자입니다. 즉, 분류하거나 예측할 쿼리 인스턴스를 수신할 때까지 모델을 구축하지 않습니다.\n",
        "- KNN은 다중 클래스 문제를 처리할 수 있습니다.\n",
        "\n",
        "3. 장점:\n",
        "- KNN은 이해하고 구현하기 쉽습니다.\n",
        "- KNN은 시끄러운 데이터와 이상값을 잘 처리할 수 있습니다.\n",
        "- KNN은 교육이 필요하지 않으므로 계산 효율이 높습니다.\n",
        "- KNN은 회귀 및 분류 작업 모두에 사용할 수 있습니다.\n",
        "\n",
        "4. 단점:\n",
        "- KNN은 거리 메트릭의 선택과 이웃 수(k)에 민감할 수 있습니다.\n",
        "- KNN은 대규모 데이터 세트의 경우 느리고 메모리를 많이 사용할 수 있습니다.\n",
        "- KNN은 고차원 데이터 세트에서 잘 수행되지 않을 수 있습니다.\n",
        "\n",
        "5. 파라미터\n",
        "    - n_neighbors : int형\n",
        "    - weights : 'uniform'(default), 'distance'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7eece986",
      "metadata": {
        "id": "7eece986",
        "outputId": "66be7cf9-a584-4576-bf45-ce10a92893d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy: 0.9777777777777777\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=4, weights='uniform')\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e18a4b29",
      "metadata": {
        "id": "e18a4b29"
      },
      "source": [
        "## 2. 회귀(Regressor)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9249980",
      "metadata": {
        "id": "b9249980"
      },
      "source": [
        "1. 선형 회귀\n",
        "- 선형 회귀는 간단하고 널리 사용되는 회귀 분석 알고리즘입니다. 종속 변수와 하나 이상의 독립 변수 간의 관계를 선형 함수로 모델링합니다.\n",
        "\n",
        "- 특징:\n",
        "    - 종속 변수와 독립 변수 사이의 선형 관계를 가정합니다.\n",
        "    - 연속 및 범주 독립 변수를 모두 처리할 수 있습니다.\n",
        "    - 과적합을 방지하기 위해 정규화할 수 있습니다.\n",
        "- 장점:\n",
        "    - 간단하고 구현하기 쉽습니다.\n",
        "    - 해석 가능한 결과를 제공합니다.\n",
        "    - 종속 변수와 독립 변수 간의 관계가 선형일 때 잘 작동합니다.\n",
        "- 단점:\n",
        "    - 종속변수와 독립변수의 관계가 비선형일 경우 제대로 작동하지 않을 수 있습니다.\n",
        "    - 무관한 독립 변수가 많을 경우 과적합이 발생할 수 있습니다.\n",
        "    \n",
        "2. 결정 트리\n",
        "- 결정 트리는 회귀 분석을 위한 강력한 알고리즘입니다. 독립 변수의 값을 기반으로 데이터를 재귀적으로 분할하여 종속 변수와 하나 이상의 독립 변수 간의 관계를 모델링합니다.\n",
        "- 특징:\n",
        "    - 연속 및 범주 독립 변수를 모두 처리할 수 있는 비선형 알고리즘입니다.\n",
        "    - 독립 변수 간의 상호 작용을 처리할 수 있습니다.\n",
        "    - 누락된 값과 이상값을 처리할 수 있습니다.\n",
        "- 장점:\n",
        "    - 해석 가능한 결과를 제공합니다.\n",
        "    - 종속 변수와 독립 변수 사이의 선형 및 비선형 관계를 모두 처리할 수 있습니다.\n",
        "    - 독립 변수 간의 상호 작용을 처리할 수 있습니다.\n",
        "- 단점:\n",
        "    - 종속 변수와 독립 변수 간의 관계가 매우 비선형적일 경우 제대로 작동하지 않을 수 있습니다.\n",
        "    - 트리가 너무 깊으면 과적합이 발생할 수 있습니다.\n",
        "    \n",
        "3. 랜덤 포레스트\n",
        "- 랜덤 포레스트는 의사 결정 트리를 기반으로 하는 회귀 분석을 위한 강력한 앙상블 알고리즘입니다. 예측의 정확성과 안정성을 향상시키기 위해 여러 의사 결정 트리를 결합합니다.\n",
        "\n",
        "- 특징:\n",
        "    - 여러 결정 트리를 결합하는 앙상블 알고리즘.\n",
        "    - 연속 및 범주 독립 변수를 모두 처리할 수 있습니다.\n",
        "    - 독립 변수 간의 상호 작용을 처리할 수 있습니다.\n",
        "- 징점:\n",
        "    - 정확하고 안정적인 예측을 제공합니다.\n",
        "    - 종속 변수와 독립 변수 사이의 선형 및 비선형 관계를 모두 처리할 수 있습니다.\n",
        "    - 독립 변수 간의 상호 작용을 처리할 수 있습니다.\n",
        "- 단점:\n",
        "    - 종속 변수와 독립 변수 간의 관계가 매우 비선형적일 경우 제대로 작동하지 않을 수 있습니다.\n",
        "    - 대규모 데이터 세트에서 교육하는 데 속도가 느릴 수 있습니다.\n",
        "    \n",
        "3. 랜덤 포레스트\n",
        "    - 랜덤 포레스트는 의사 결정 트리를 기반으로 하는 회귀 분석을 위한 강력한 앙상블 알고리즘입니다. 예측의 정확성과 안정성을 향상시키기 위해 여러 의사 결정 트리를 결합합니다.\n",
        "- 특징:\n",
        "    - 여러 결정 트리를 결합하는 앙상블 알고리즘.\n",
        "    - 연속 및 범주 독립 변수를 모두 처리할 수 있습니다.\n",
        "    - 독립 변수 간의 상호 작용을 처리할 수 있습니다.\n",
        "- 장점:\n",
        "    - 정확하고 안정적인 예측을 제공합니다.\n",
        "    - 종속 변수와 독립 변수 사이의 선형 및 비선형 관계를 모두 처리할 수 있습니다.\n",
        "    - 독립 변수 간의 상호 작용을 처리할 수 있습니다.\n",
        "\n",
        "- 단점:\n",
        "    - 종속 변수와 독립 변수 간의 관계가 매우 비선형적일 경우 제대로 작동하지 않을 수 있습니다.\n",
        "    - 대규모 데이터 세트에서 교육하는 데 속도가 느릴 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b9e371c8",
      "metadata": {
        "id": "b9e371c8"
      },
      "source": [
        "### Ridge, Lasso, ElasticNet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed50a12e",
      "metadata": {
        "id": "ed50a12e"
      },
      "source": [
        "1. Ridge (능선)\n",
        "- 특징:\n",
        "    - 과적합을 방지하기 위해 목적 함수에 정규화 항을 추가합니다. (**L2규제**)\n",
        "    - 예측변수 간의 다중공선성을 다룰 수 있다.\n",
        "- 장점:\n",
        "    - 다중공선성이 존재하는 경우 일반 최소자승회귀보다 데이터에 더 적합할 수 있습니다.\n",
        "    - 예측 변수가 많을 때 잘 작동합니다.\n",
        "\n",
        "- 단점:\n",
        "    - 계수가 매우 작거나 0인 예측 변수가 많은 경우 성능이 좋지 않을 수 있습니다.\n",
        "\n",
        "- 파라미터\n",
        "    - alpha: 정규화 강도 매개변수. 알파 값이 높을수록 정규화가 강화되어 과적합을 방지할 수 있습니다.\n",
        "    - fit_intercept: 모델에 절편 항을 맞출지 여부. 기본값은 참입니다.\n",
        "    - max_iter: 솔버가 수렴하는 최대 반복 횟수. 기본값은 없음(솔버에서 설정)입니다.\n",
        "    - normalize: 입력 데이터를 정규화할지 여부. 기본값은 거짓입니다.\n",
        "    - solver: 최적화 문제를 해결하는 데 사용되는 알고리즘입니다. 옵션은 'auto'(기본값), 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag' 또는 'saga'입니다.\n",
        "    - tol: 솔버가 수렴하는 허용오차. 기본값은 0.001입니다.\n",
        "\n",
        "\n",
        "2. Lasso (올가미 회귀):\n",
        "- 특징:\n",
        "    - 과적합을 방지하기 위해 계수의 절대값을 사용하는 목적 함수에 정규화 항을 추가합니다. (**L1규제**)\n",
        "    - 일부 계수를 0으로 설정하여 기능 선택에 사용할 수 있습니다.\n",
        "\n",
        "- 장점:\n",
        "    - 일부 계수를 0으로 설정하여 희소 솔루션을 제공할 수 있으므로 모델을 더 쉽게 해석하고 과적합을 줄일 수 있습니다.\n",
        "    - 예측 변수가 많을 때 잘 작동할 수 있습니다.\n",
        "\n",
        "- 단점:\n",
        "    - 계수가 매우 작거나 0인 예측 변수가 많은 경우 잘 작동하지 않을 수 있습니다.\n",
        "- 파라미터\n",
        "    - alpha : 정규화 강도 매개변수. 알파 값이 높을수록 정규화가 강화되어 과적합을 방지할 수 있습니다.\n",
        "    - fit_intercept: 모델에 절편 항을 맞출지 여부. 기본값은 True입니다.\n",
        "    - max_iter: 솔버가 수렴하는 최대 반복 횟수. 기본값은 1000입니다.\n",
        "    - normalize: 입력 데이터를 정규화할지 여부. 기본값은 False 입니다.\n",
        "    - selection : 기능을 선택하는 데 사용되는 방법입니다. 옵션은 'cyclic'(기본값) 또는 'random'입니다.\n",
        "    - tol: 솔버가 수렴하는 허용오차. 기본값은 0.0001입니다.\n",
        "\n",
        "\n",
        "3. ElasticNet 회귀:\n",
        "- 특징:\n",
        "    - 과적합을 방지하기 위해 L1 및 L2 정규화 항을 결합합니다.\n",
        "    - 예측변수 간의 다중공선성을 다룰 수 있다.\n",
        "    - 많은 기능을 가진 고차원 데이터 세트를 처리할 수 있습니다.\n",
        "    - L1 및 L2 정규화를 결합하여 모델 성능 향상\n",
        "\n",
        "\n",
        "- 장점:\n",
        "    - Lasso 회귀와 같은 희소 솔루션을 제공하는 동시에 다음과 같은 다중 공선성을 처리할 수 있습니다.\n",
        "    - 특징이 많은 데이터셋에 적합\n",
        "    - 가장 중요한 기능을 선택하는 데 도움이 됩니다.\n",
        "    - 다중공선성을 잘 다룬다.\n",
        "\n",
        "- 단점\n",
        "    - 일부 다른 회귀 모델보다 느릴 수 있음\n",
        "    - 최적의 성능을 위해 하이퍼파라미터를 신중하게 선택해야 함\n",
        "    \n",
        "- 하이퍼 파라미터\n",
        "    - alpha: L1과 L2 정규화 간의 균형을 제어합니다. 알파 값이 높을수록 L1 정규화가 증가하고 모델에 사용되는 기능 수가 줄어듭니다.\n",
        "    - l1_ratio: L1 및 L2 정규화 비율을 제어합니다. 값 1은 순수한 L1 정규화를 나타내고 0은 순수한 L2 정규화를 나타냅니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f43fb0af",
      "metadata": {
        "id": "f43fb0af",
        "outputId": "b24be9e6-5219-454d-b88c-52934eeb1a11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ridge regression:\n",
            "  Coefficients: [  45.36737726  -76.66608563  291.33883165  198.99581745   -0.53030959\n",
            "  -28.57704987 -144.51190505  119.26006559  230.22160832  112.14983004]\n",
            "  Intercept: 152.241675211113\n",
            "  Mean squared error: 3077.42\n",
            "Lasso regression:\n",
            "  Coefficients: [  0.          -0.         413.43184792  34.83051518   0.\n",
            "   0.          -0.           0.         258.15289363   0.        ]\n",
            "  Intercept: 152.6639595689638\n",
            "  Mean squared error: 3403.58\n",
            "ElasticNet regression:\n",
            "  Coefficients: [ 0.40100389  0.          3.41353382  2.32614375  0.4595766   0.12555225\n",
            " -1.78311241  2.12401019  3.07139136  1.90618344]\n",
            "  Intercept: 153.71775116932596\n",
            "  Mean squared error: 5311.21\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_diabetes\n",
        "from sklearn.linear_model import Ridge, Lasso, ElasticNet\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "X, y = load_diabetes(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "ridge = Ridge(alpha=1.0, fit_intercept=True, max_iter=None, \n",
        "              solver='auto', tol=0.001)\n",
        "lasso = Lasso(alpha=1.0, fit_intercept=True, max_iter=1000, \n",
        "              selection='cyclic', tol=0.0001)\n",
        "elasticnet = ElasticNet(alpha=1.0, l1_ratio=0.5)\n",
        "\n",
        "ridge.fit(X_train, y_train)\n",
        "lasso.fit(X_train, y_train)\n",
        "elasticnet.fit(X_train, y_train)\n",
        "\n",
        "y_pred_ridge = ridge.predict(X_test)\n",
        "y_pred_lasso = lasso.predict(X_test)\n",
        "y_pred_elasticnet = elasticnet.predict(X_test)\n",
        "\n",
        "mse_ridge = mean_squared_error(y_test, y_pred_ridge)\n",
        "mse_lasso = mean_squared_error(y_test, y_pred_lasso)\n",
        "mse_elasticnet = mean_squared_error(y_test, y_pred_elasticnet)\n",
        "\n",
        "print(\"Ridge regression:\")\n",
        "print(f\"  Coefficients: {ridge.coef_}\")\n",
        "print(f\"  Intercept: {ridge.intercept_}\")\n",
        "print(f\"  Mean squared error: {mse_ridge:.2f}\")\n",
        "\n",
        "print(\"Lasso regression:\")\n",
        "print(f\"  Coefficients: {lasso.coef_}\")\n",
        "print(f\"  Intercept: {lasso.intercept_}\")\n",
        "print(f\"  Mean squared error: {mse_lasso:.2f}\")\n",
        "\n",
        "print(\"ElasticNet regression:\")\n",
        "print(f\"  Coefficients: {elasticnet.coef_}\")\n",
        "print(f\"  Intercept: {elasticnet.intercept_}\")\n",
        "print(f\"  Mean squared error: {mse_elasticnet:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1852e062",
      "metadata": {
        "id": "1852e062"
      },
      "source": [
        "## 3. 군집 (Clustering)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f31bac2",
      "metadata": {
        "id": "6f31bac2"
      },
      "source": [
        "군집 분석은 유사한 객체를 특성에 따라 함께 그룹화하기 위해 비지도 학습에 사용되는 기술입니다. 여러 클러스터링 알고리즘을 사용할 수 있으며 각각 고유한 특성, 강점 및 약점이 있습니다.\n",
        "\n",
        "1. K-평균 (K-Means)\n",
        "    - K-평균은 특징의 유사성을 기반으로 데이터를 K 클러스터로 분할하는 널리 사용되는 클러스터링 알고리즘입니다. 알고리즘은 각 데이터 포인트를 가장 가까운 군집 중심에 반복적으로 할당하고 새 군집 중심을 계산하며 수렴될 때까지 반복합니다.\n",
        "- 특징:\n",
        "    - 사전에 클러스터 수를 지정해야 합니다.\n",
        "    - 대용량 데이터 세트와 잘 작동합니다.\n",
        "    - 클러스터 센터의 초기 무작위 선택에 민감합니다.\n",
        "\n",
        "- 장점:\n",
        "    - 계산적으로 효율적이고 구현하기 쉽습니다.\n",
        "    - 클러스터가 잘 분리되어 있고 데이터가 균일하게 분산되어 있을 때 잘 작동합니다.\n",
        "\n",
        "- 단점:\n",
        "    - 클러스터의 모양이 불규칙하거나 밀도가 다른 경우 제대로 작동하지 않을 수 있습니다.\n",
        "    - 데이터의 차원이 높을 경우 잘 동작하지 않을 수 있습니다.\n",
        "    \n",
        "2. Hierarchical Clustering (계층적 클러스터링)\n",
        "    - 계층적 클러스터링은 더 작은 클러스터를 더 큰 클러스터로 반복적으로 병합(집합)하거나 더 큰 클러스터를 더 작은 클러스터로 반복적으로 분할(분할)하여 클러스터 계층을 구축하는 클러스터링 알고리즘입니다.\n",
        "\n",
        "- 특징:\n",
        "    - 클러스터 간의 계층적 관계를 보여주는 덴드로그램을 생성합니다.\n",
        "    - 사전에 클러스터 수를 지정할 필요가 없습니다.\n",
        "    - 다양한 크기와 모양의 클러스터를 처리할 수 있습니다.\n",
        "\n",
        "- 장점:\n",
        "    - 클러스터링 계층의 시각적 표현을 제공합니다.\n",
        "    - 다양한 크기와 모양의 클러스터를 처리할 수 있습니다.\n",
        "\n",
        "- 단점:\n",
        "    - 대규모 데이터 세트의 경우 계산 비용이 많이 들 수 있습니다.\n",
        "    - 복잡한 데이터 세트에 대해 최적이 아닌 솔루션을 생성할 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a80c16e0",
      "metadata": {
        "id": "a80c16e0"
      },
      "source": [
        "### K-Means"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf70163",
      "metadata": {
        "id": "aaf70163",
        "outputId": "af1a8695-c885-4653-e2a3-4fb78669e2e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X: [[ 5.02007669  2.58375543]\n",
            " [ 3.23236714  1.195353  ]\n",
            " [-6.10792848 -9.72865221]\n",
            " [ 5.19966928  3.05395041]\n",
            " [ 1.38081864  4.5933741 ]]\n",
            "y: [1 1 2 1 4]\n",
            "labels: [0 0 2 0 4]\n",
            "centers: [[ 4.65960568  1.89528052]\n",
            " [-2.50265159  9.03963769]\n",
            " [-6.68630691 -6.81139455]\n",
            " [-8.80798056  7.40425704]\n",
            " [ 2.01603476  4.27139248]]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import KMeans\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# Generate random dataset\n",
        "X, y = make_blobs(n_samples=1000, centers=5, random_state=42)\n",
        "print('X:', X[:5])\n",
        "print('y:', y[:5])\n",
        "# Fit K-means model to data\n",
        "kmeans = KMeans(n_clusters=5, random_state=42)\n",
        "kmeans.fit(X)\n",
        "\n",
        "# Get cluster labels and cluster centers\n",
        "labels = kmeans.labels_\n",
        "centers = kmeans.cluster_centers_\n",
        "print('labels:', labels[:5])\n",
        "print('centers:', centers[:5])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dead0c2",
      "metadata": {
        "id": "3dead0c2"
      },
      "source": [
        "### 계층적군집분석"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d6fcdb42",
      "metadata": {
        "id": "d6fcdb42",
        "outputId": "2d7d7941-55a9-4204-d46b-598b60a5e842"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAGECAYAAAA4OOv5AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/P9b71AAAACXBIWXMAAA9hAAAPYQGoP6dpAABS9UlEQVR4nO3dd1yV5f/H8ddhIwgIIiig4gRnuVHLEeYsV5ojd5p7paX9cluOcGQ5ysyZqaSRI/fMgak4c2GKoAwVBZQN5/794Zc7joACggeOn+fjcR5y7nGdz32fc97nuq/79hyNoigKQgghDJaRvgsQQgiRvyTohRDCwEnQCyGEgZOgF0IIAydBL4QQBk6CXgghDJwEvRBCGDgJeiGEMHAS9EIIYeAk6IV4jrJly9K3b199lyHES5GgF3q3atUqNBqNerOwsKBUqVK0bNmSRYsW8fjxY32XKEShZqLvAoRIM336dNzd3UlOTiY8PJxDhw4xevRo5s+fz9atW6lRo4a+SxSiUJKgFwVG69atqVOnjnp/4sSJHDhwgHbt2vH+++9z5coVLC0t9Vhh5mJjY7Gysnolj5WQkICZmRlGRnIwLrJPXi2iQGvevDmTJk3i9u3brFu3Tp1+9epVPvjgA+zt7bGwsKBOnTps3bpVZ920IaFjx44xduxYHB0dsbKyomPHjty/f19nWUVRmDlzJq6urhQpUoRmzZrxzz//ZKgnrc3Dhw8zdOhQSpQogaurqzp/yZIlVK1aFXNzc0qVKsWwYcOIiorK0M7ixYspV64clpaW1KtXj7/++oumTZvStGlTdZlDhw6h0WjYsGEDX375JS4uLhQpUoSYmBgePnzIuHHjqF69OtbW1tjY2NC6dWvOnz+v8zhpbWzatIlp06bh4uJC0aJF+eCDD4iOjiYxMZHRo0dTokQJrK2t6devH4mJiTl5ikQhID16UeD16tWLL774gj179jBw4ED++ecfGjVqhIuLCxMmTMDKyopNmzbRoUMHNm/eTMeOHXXWHzFiBMWKFWPKlCkEBQWxcOFChg8fzsaNG9VlJk+ezMyZM2nTpg1t2rQhICCAd999l6SkpExrGjp0KI6OjkyePJnY2FgApk6dyrRp0/D29mbIkCFcu3aNpUuXcurUKY4dO4apqSkAS5cuZfjw4bz11luMGTOGoKAgOnToQLFixXQ+NNLMmDEDMzMzxo0bR2JiImZmZly+fBk/Pz+6dOmCu7s7ERER/PDDDzRp0oTLly9TqlQpnTZmzZqFpaUlEyZM4MaNG3z33XeYmppiZGTEo0ePmDp1Kv7+/qxatQp3d3cmT578Us+ZKGAUIfRs5cqVCqCcOnUqy2VsbW2VN998U1EURXnnnXeU6tWrKwkJCep8rVarNGzYUKlYsWKGdr29vRWtVqtOHzNmjGJsbKxERUUpiqIo9+7dU8zMzJS2bdvqLPfFF18ogNKnT58MbTZu3FhJSUlRp6e18e677yqpqanq9O+//14BlJ9//llRFEVJTExUHBwclLp16yrJycnqcqtWrVIApUmTJuq0gwcPKoBSrlw5JS4uTmd/JCQk6DyOoijKrVu3FHNzc2X69OkZ2qhWrZqSlJSkTu/evbui0WiU1q1b67Th5eWllClTRhGGRYZuRKFgbW3N48ePefjwIQcOHKBr1648fvyYBw8e8ODBAyIjI2nZsiWBgYHcvXtXZ91Bgwah0WjU+2+99Rapqancvn0bgH379pGUlMSIESN0lhs9enSW9QwcOBBjY2P1flobo0eP1hk/HzhwIDY2NuzYsQOA06dPExkZycCBAzEx+e+AumfPnhQrVizTx+rTp0+GcxPm5ubq46SmphIZGYm1tTWVK1cmICAgQxu9e/dWjygA6tevj6Io9O/fX2e5+vXrExISQkpKSpbbLgofGboRhcKTJ08oUaIEN27cQFEUJk2axKRJkzJd9t69e7i4uKj3S5curTM/LVAfPXoEoAZ+xYoVdZZzdHTMMnzd3d117qe1UblyZZ3pZmZmlCtXTp2f9m+FChV0ljMxMaFs2bLZeiwArVbLt99+y5IlS7h16xapqanqPAcHhwzLP7sPbG1tAXBzc8swXavVEh0dnWk7onCSoBcF3p07d4iOjqZChQpotVoAxo0bR8uWLTNd/tkQTd/zTk95iV/RfJVX/2T2WF9//TWTJk2if//+zJgxA3t7e4yMjBg9erS6j9LLah/kx74RBY8EvSjw1q5dC0DLli0pV64cAKampnh7e+dJ+2XKlAEgMDBQbR/g/v37aq8/u21cu3ZNp42kpCRu3bql1pq23I0bN2jWrJm6XEpKCkFBQdn+vwK//fYbzZo1Y8WKFTrTo6KiKF68eLbaEK8PGaMXBdqBAweYMWMG7u7u9OzZkxIlStC0aVN++OEHwsLCMiz/7GWT2eHt7Y2pqSnfffedTk924cKFOWrDzMyMRYsW6bSxYsUKoqOjadu2LQB16tTBwcGB5cuX64yD//LLL9n+UIGnPfFne92+vr4Zzk8IAdKjFwXIzp07uXr1KikpKURERHDgwAH27t1LmTJl2Lp1KxYWFsDTa9AbN25M9erVGThwIOXKlSMiIoITJ05w586dDNeSv4ijoyPjxo1j1qxZtGvXjjZt2nD27Fl27tyZ7d6xo6MjEydOZNq0abRq1Yr333+fa9eusWTJEurWrctHH30EPB2znzp1KiNGjKB58+Z07dqVoKAgVq1aRfny5XVOBj9Pu3btmD59Ov369aNhw4ZcvHiRX375RedoQog0EvSiwEi7dtvMzAx7e3uqV6/OwoUL6devH0WLFlWXq1KlCqdPn2batGmsWrWKyMhISpQowZtvvpnr679nzpyJhYUFy5Yt4+DBg9SvX589e/aoPfHsmDp1Ko6Ojnz//feMGTMGe3t7Bg0axNdff61zxcvw4cNRFIV58+Yxbtw4atasydatWxk5cqT6YfYiX3zxBbGxsaxfv56NGzdSq1YtduzYwYQJE3K87cLwaRQ56yKE3mm1WhwdHenUqRPLly/XdznCwMgYvRCvWEJCQobx9TVr1vDw4UOdr0AQIq9Ij16IV+zQoUOMGTOGLl264ODgQEBAACtWrMDT05MzZ85gZmam7xKFgZExeiFesbJly+Lm5saiRYt4+PAh9vb29O7dm9mzZ0vIi3whPXohhDBwMkYvhBAGToJeCCEMnMGP0Wu1WkJDQylatGi2/zOKEEIUZIqi8PjxY0qVKpWtXxsz+KAPDQ3N8A19QghhCEJCQjL9sZpnGXzQp/2PypCQEGxsbPRcjRBCvLyYmBjc3Nx0/sf48xh80KcN19jY2EjQCyEMSnaHo+VkrBBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAMnQS+EEAZOgl4IIQycBL0QQhg4g/+fsfqmKArxyan6LkMUIpamxvIFfCJPSdDnI0VR+GDZCc7cfqTvUkQhUqdMMXwHe0nYizwjQzf5KD45VUJe5Njp24/kKFDkKenRvyKnv/SmiJmxvssQBVhcUip1Zu7TdxnCAEnQvyJFzIwpYia7Wwjx6snQjRBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAOn16BPTU1l0qRJuLu7Y2lpSfny5ZkxYwaKoqjLKIrC5MmTKVmyJJaWlnh7exMYGKjHqoUQonDRa9DPmTOHpUuX8v3333PlyhXmzJnD3Llz+e6779Rl5s6dy6JFi1i2bBknT57EysqKli1bkpCQoMfKhRCi8NDr/+A5fvw47du3p23btgCULVuWX3/9lb///ht42ptfuHAhX375Je3btwdgzZo1ODk54efnR7du3fRWuxBCFBZ67dE3bNiQ/fv3c/36dQDOnz/P0aNHad26NQC3bt0iPDwcb29vdR1bW1vq16/PiRMnMm0zMTGRmJgYnZsQQrzO9NqjnzBhAjExMXh4eGBsbExqaipfffUVPXv2BCA8PBwAJycnnfWcnJzUec+aNWsW06ZNy9/ChRCiENFrj37Tpk388ssvrF+/noCAAFavXo2Pjw+rV6/OdZsTJ04kOjpavYWEhORhxUIIUfjotUc/fvx4JkyYoI61V69endu3bzNr1iz69OmDs7MzABEREZQsWVJdLyIigjfeeCPTNs3NzTE3N8/32oUQorDQa48+Li4OIyPdEoyNjdFqtQC4u7vj7OzM/v371fkxMTGcPHkSLy+vV1qrEEIUVnrt0b/33nt89dVXlC5dmqpVq3L27Fnmz59P//79AdBoNIwePZqZM2dSsWJF3N3dmTRpEqVKlaJDhw76LF0IIQoNvQb9d999x6RJkxg6dCj37t2jVKlSfPLJJ0yePFld5rPPPiM2NpZBgwYRFRVF48aN2bVrFxYWFnqsXAghCg+Nkv6/oRqgmJgYbG1tiY6OxsbG5pU+dlxSClUm7wbg8vSW8sMj4rnk9SKyK6e5Jt91I4QQBk6CXgghDJwEvRBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAMnQS+EEAZOgl4IIQycBL0QQhg4CXohhDBwEvRCCGHgJOiFEMLASdALIYSBk6AXQggDJ0EvhBAGToJeCCEMnAS9EEIYOAl6IYQwcBL0Qghh4CTohRDCwEnQCyGEgZOgF0IIAydBL4QQBk6vQV+2bFk0Gk2G27BhwwBISEhg2LBhODg4YG1tTefOnYmIiNBnyUIIUejoNehPnTpFWFiYetu7dy8AXbp0AWDMmDFs27YNX19fDh8+TGhoKJ06ddJnyUIIUeiY6PPBHR0dde7Pnj2b8uXL06RJE6Kjo1mxYgXr16+nefPmAKxcuRJPT0/8/f1p0KBBpm0mJiaSmJio3o+Jicm/DRBCiEKgwIzRJyUlsW7dOvr3749Go+HMmTMkJyfj7e2tLuPh4UHp0qU5ceJElu3MmjULW1tb9ebm5vYqyhdCiAKrwAS9n58fUVFR9O3bF4Dw8HDMzMyws7PTWc7JyYnw8PAs25k4cSLR0dHqLSQkJB+rFkKIgk+vQzfprVixgtatW1OqVKmXasfc3Bxzc/M8qkoIIQq/AhH0t2/fZt++fWzZskWd5uzsTFJSElFRUTq9+oiICJydnfVQpdAnRVGIT07Vdxn5Ki4pJdO/DZmlqTEajUbfZRi8AhH0K1eupESJErRt21adVrt2bUxNTdm/fz+dO3cG4Nq1awQHB+Pl5aWvUoUeKIrCB8tOcOb2I32X8srUmblf3yW8EnXKFMN3sJeEfT7Te9BrtVpWrlxJnz59MDH5rxxbW1sGDBjA2LFjsbe3x8bGhhEjRuDl5ZXlFTfCMMUnp75WIf86OX37EfHJqRQx03sUGTS97919+/YRHBxM//79M8xbsGABRkZGdO7cmcTERFq2bMmSJUv0UKUoKE5/6U0RM2N9lyFeUlxSKnVm7tN3Ga8NvQf9u+++i6Iomc6zsLBg8eLFLF68+BVXJQqqImbG0vsTIocKzOWVQggh8ocEvRBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAMnQS+EEAZOgl4IIQycBL0QQhg4CXohhDBwEvRCCGHgJOiFEMLASdALIYSBk6AXQggDJ0EvhBAGToJeCCEMnAS9EEIYOAl6IYQwcBL0Qghh4CTohRDCwEnQCyGEgZOgF0IIAydBL4QQBk7vQX/37l0++ugjHBwcsLS0pHr16pw+fVqdrygKkydPpmTJklhaWuLt7U1gYKAeKxZCiMJFr0H/6NEjGjVqhKmpKTt37uTy5cvMmzePYsWKqcvMnTuXRYsWsWzZMk6ePImVlRUtW7YkISFBj5ULIUThYaLPB58zZw5ubm6sXLlSnebu7q7+rSgKCxcu5Msvv6R9+/YArFmzBicnJ/z8/OjWrVuGNhMTE0lMTFTvx8TE5OMWCCFEwafXHv3WrVupU6cOXbp0oUSJErz55pssX75cnX/r1i3Cw8Px9vZWp9na2lK/fn1OnDiRaZuzZs3C1tZWvbm5ueX7dgghREGm16C/efMmS5cupWLFiuzevZshQ4YwcuRIVq9eDUB4eDgATk5OOus5OTmp8541ceJEoqOj1VtISEj+boQQQhRweh260Wq11KlTh6+//hqAN998k0uXLrFs2TL69OmTqzbNzc0xNzfPyzKFEKJQ02uPvmTJklSpUkVnmqenJ8HBwQA4OzsDEBERobNMRESEOk8IIcTz6TXoGzVqxLVr13SmXb9+nTJlygBPT8w6Ozuzf/9+dX5MTAwnT57Ey8vrldYqhBCFlV6HbsaMGUPDhg35+uuv6dq1K3///Tc//vgjP/74IwAajYbRo0czc+ZMKlasiLu7O5MmTaJUqVJ06NBBn6ULIUShodegr1u3Lr///jsTJ05k+vTpuLu7s3DhQnr27Kku89lnnxEbG8ugQYOIioqicePG7Nq1CwsLCz1WLoQQhYdegx6gXbt2tGvXLsv5Go2G6dOnM3369FdYlRBCGA69fwWCEEKI/CVBL4QQBk6CXgghDJwEvRBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAMnQS+EEAZOgl4IIQycBL0QQhg4CXohhDBwEvRCCGHgJOiFEMLASdALIYSBk6AXQggDJ0EvhBAGToJeCCEMnAS9EEIYOAl6IYQwcBL0Qghh4F466BMSEvKiDiGEEPkkV0Gv1WqZMWMGLi4uWFtbc/PmTQAmTZrEihUr8rRAIYQQLydXQT9z5kxWrVrF3LlzMTMzU6dXq1aNn376KdvtTJ06FY1Go3Pz8PBQ5yckJDBs2DAcHBywtramc+fORERE5KZkIYR4beUq6NesWcOPP/5Iz549MTY2VqfXrFmTq1ev5qitqlWrEhYWpt6OHj2qzhszZgzbtm3D19eXw4cPExoaSqdOnXJTshBCvLZMcrPS3bt3qVChQobpWq2W5OTknBVgYoKzs3OG6dHR0axYsYL169fTvHlzAFauXImnpyf+/v40aNAg0/YSExNJTExU78fExOSoHiGEMDS56tFXqVKFv/76K8P03377jTfffDNHbQUGBlKqVCnKlStHz549CQ4OBuDMmTMkJyfj7e2tLuvh4UHp0qU5ceJElu3NmjULW1tb9ebm5pajeoQQwtDkqkc/efJk+vTpw927d9FqtWzZsoVr166xZs0atm/fnu126tevz6pVq6hcuTJhYWFMmzaNt956i0uXLhEeHo6ZmRl2dnY66zg5OREeHp5lmxMnTmTs2LHq/ZiYGAl7IcRrLVdB3759e7Zt28b06dOxsrJi8uTJ1KpVi23bttGiRYtst9O6dWv17xo1alC/fn3KlCnDpk2bsLS0zE1pmJubY25unqt1hRDCEOUq6AHeeust9u7dm5e1YGdnR6VKlbhx4wYtWrQgKSmJqKgonV59REREpmP6QgghMperMfpTp05x8uTJDNNPnjzJ6dOnc13MkydP+PfffylZsiS1a9fG1NSU/fv3q/OvXbtGcHAwXl5euX4MIYR43eQq6IcNG0ZISEiG6Xfv3mXYsGHZbmfcuHEcPnyYoKAgjh8/TseOHTE2NqZ79+7Y2toyYMAAxo4dy8GDBzlz5gz9+vXDy8sryytuhBBCZJSroZvLly9Tq1atDNPffPNNLl++nO127ty5Q/fu3YmMjMTR0ZHGjRvj7++Po6MjAAsWLMDIyIjOnTuTmJhIy5YtWbJkSW5KFkKI11augt7c3JyIiAjKlSunMz0sLAwTk+w3uWHDhufOt7CwYPHixSxevDg3ZQohhCCXQzfvvvsuEydOJDo6Wp0WFRXFF198kaOrboQQQuS/XPXofXx8ePvttylTpoz6H6TOnTuHk5MTa9euzdMChRBCvJxcBb2LiwsXLlzgl19+4fz581haWtKvXz+6d++OqalpXtcohBDiJeT6OnorKysGDRqUl7UIIYTIB7kO+sDAQA4ePMi9e/fQarU68yZPnvzShQkhhMgbuQr65cuXM2TIEIoXL46zszMajUadp9FoJOiFEKIAyVXQz5w5k6+++orPP/88r+sRQgiRx3J1eeWjR4/o0qVLXtcihBAiH+Qq6Lt06cKePXvyuhYhhBD5IFdDNxUqVGDSpEn4+/tTvXr1DJdUjhw5Mk+KE0II8fJyFfQ//vgj1tbWHD58mMOHD+vM02g0EvRCCFGA5Crob926ldd1CCGEyCe5GqMXQghReOT6P0zduXOHrVu3EhwcTFJSks68+fPnv3RhQggh8kaugn7//v28//77lCtXjqtXr1KtWjWCgoJQFCXT76kXQgihP7kaupk4cSLjxo3j4sWLWFhYsHnzZkJCQmjSpIlcXy+EEAVMroL+ypUr9O7dGwATExPi4+OxtrZm+vTpzJkzJ08LFEII8XJyFfRWVlbquHzJkiX5999/1XkPHjzIm8qEEELkiVyN0Tdo0ICjR4/i6elJmzZt+PTTT7l48SJbtmyRH+4WQogCJldBP3/+fJ48eQLAtGnTePLkCRs3bqRixYpyxY0QQhQwuQr69D8KbmVlxbJly/KsICGEEHkrV2P05cqVIzIyMsP0qKgonQ8BIYQQ+peroA8KCiI1NTXD9MTERO7evfvSRQkhhMg7ORq62bp1q/r37t27sbW1Ve+npqayf/9+ypYtm2fFCSGEeHk5CvoOHToAT7+hsk+fPjrzTE1NKVu2LPPmzctVIbNnz2bixImMGjWKhQsXApCQkMCnn37Khg0bSExMpGXLlixZsgQnJ6dcPYYQQryOcjR0o9Vq0Wq1lC5dWv1R8LRbYmIi165do127djku4tSpU/zwww/UqFFDZ/qYMWPYtm0bvr6+HD58mNDQUDp16pTj9oUQ4nWWqzH6W7duUbx4cZ1pUVFRuSrgyZMn9OzZk+XLl1OsWDF1enR0NCtWrGD+/Pk0b96c2rVrs3LlSo4fP46/v3+uHksIIV5HuQr6OXPmsHHjRvV+ly5dsLe3x8XFhfPnz+eorWHDhtG2bVu8vb11pp85c4bk5GSd6R4eHpQuXZoTJ05k2V5iYiIxMTE6NyGEeJ3lKuiXLVuGm5sbAHv37mXfvn3s2rWL1q1bM378+Gy3s2HDBgICApg1a1aGeeHh4ZiZmWFnZ6cz3cnJifDw8CzbnDVrFra2tuotrU4hhHhd5eo/TIWHh6sBun37drp27cq7775L2bJlqV+/frbaCAkJYdSoUezduxcLC4vclJGpiRMnMnbsWPV+TEyMhL0Q4rWWqx59sWLFCAkJAWDXrl3q8IqiKJleX5+ZM2fOcO/ePWrVqoWJiQkmJiYcPnyYRYsWYWJigpOTE0lJSRnG/iMiInB2ds6yXXNzc2xsbHRuQgjxOstVj75Tp0706NGDihUrEhkZSevWrQE4e/YsFSpUyFYb77zzDhcvXtSZ1q9fPzw8PPj8889xc3PD1NSU/fv307lzZwCuXbtGcHAwXl5euSlbCCFeS7kK+gULFlC2bFlCQkKYO3cu1tbWAISFhTF06NBstVG0aFGqVaumM83KygoHBwd1+oABAxg7diz29vbY2NgwYsQIvLy85BsyhRAiB3IV9KampowbNy7D9DFjxrx0QektWLAAIyMjOnfurPMfpoQQQmRftoN+69attG7dGlNTU52vQsjM+++/n6tiDh06pHPfwsKCxYsXs3jx4ly1J4QQIgdB36FDB8LDwylRooT6VQiZ0Wg02T4hK4QQIv9lO+i1Wm2mfwshhCjYcjxGr9VqWbVqFVu2bCEoKAiNRkO5cuXo3LkzvXr1QqPR5EedQgghcilH19ErisL777/Pxx9/zN27d6levTpVq1YlKCiIvn370rFjx/yqUwghRC7lqEe/atUqjhw5wv79+2nWrJnOvAMHDtChQwfWrFlD796987RIIYQQuZejHv2vv/7KF198kSHkAZo3b86ECRP45Zdf8qw4IYQQLy9HQX/hwgVatWqV5fzWrVvn+NsrhRBC5K8cBf3Dhw+f++tOTk5OPHr06KWLEkIIkXdyFPSpqamYmGQ9rG9sbExKSspLFyWEECLv5OhkrKIo9O3bF3Nz80znJyYm5klRQggh8k6Ogv7ZHwTPjFxxI4QQBUuOgn7lypX5VYcQQoh8kqsfHhFCCFF4SNALIYSBk6AXQggDJ0EvhBAGToJeCCEMnAS9EEIYOAl6IYQwcBL0Qghh4CTohRDCwOX4pwSFEIWboigo8fF6rUGblPrf33HxaFOM9VgNaCwtDfpnUCXohXiNKIrC7R49iT97Vq91JBibwXtfAxDYqDEWqUl6rceyVi3K/LLOYMNegl6I14gSH6/3kAewSE1ip984fZehig8IQImPR1OkiL5LyRd6DfqlS5eydOlSgoKCAKhatSqTJ0+mdevWACQkJPDpp5+yYcMGEhMTadmyJUuWLHnuj58IIbKn4rGjGFla6rsMvdLGxxPYqLG+y8h3eg16V1dXZs+eTcWKFVEUhdWrV9O+fXvOnj1L1apVGTNmDDt27MDX1xdbW1uGDx9Op06dOHbsmD7LFsIgGFlaYmSgPVihS69B/9577+nc/+qrr1i6dCn+/v64urqyYsUK1q9fT/PmzYGnX5Ps6emJv78/DRo00EfJQghR6BSYyytTU1PZsGEDsbGxeHl5cebMGZKTk/H29laX8fDwoHTp0pw4cSLLdhITE4mJidG5CSHE60zvQX/x4kWsra0xNzdn8ODB/P7771SpUoXw8HDMzMyws7PTWd7JyYnw8PAs25s1axa2trbqzc3NLZ+3QAghCja9B33lypU5d+4cJ0+eZMiQIfTp04fLly/nur2JEycSHR2t3kJCQvKwWiGEKHz0fnmlmZkZFSpUAKB27dqcOnWKb7/9lg8//JCkpCSioqJ0evURERE4Oztn2Z65uXmWP14uhBCvI7336J+l1WpJTEykdu3amJqasn//fnXetWvXCA4OxsvLS48VCiFE4aLXHv3EiRNp3bo1pUuX5vHjx6xfv55Dhw6xe/dubG1tGTBgAGPHjsXe3h4bGxtGjBiBl5eXXHEjhBA5oNegv3fvHr179yYsLAxbW1tq1KjB7t27adGiBQALFizAyMiIzp076/yHKSGEENmn16BfsWLFc+dbWFiwePFiFi9e/IoqEkIIw1PgxuiFEELkLQl6IYQwcBL0Qghh4CTohRDCwEnQCyGEgZOgF0IIAydBL4QQBk6CXgghDJwEvRBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAMnQS+EEAZOgl4IIQycBL0QQhg4CXohhDBwEvRCCGHgJOiFEMLASdALIYSBk6AXQggDJ0EvhBAGToJeCCEMnF6DftasWdStW5eiRYtSokQJOnTowLVr13SWSUhIYNiwYTg4OGBtbU3nzp2JiIjQU8VCCFH46DXoDx8+zLBhw/D392fv3r0kJyfz7rvvEhsbqy4zZswYtm3bhq+vL4cPHyY0NJROnTrpsWohhChcTPT54Lt27dK5v2rVKkqUKMGZM2d4++23iY6OZsWKFaxfv57mzZsDsHLlSjw9PfH396dBgwb6KFsIIQqVAjVGHx0dDYC9vT0AZ86cITk5GW9vb3UZDw8PSpcuzYkTJzJtIzExkZiYGJ2bEEK8zgpM0Gu1WkaPHk2jRo2oVq0aAOHh4ZiZmWFnZ6ezrJOTE+Hh4Zm2M2vWLGxtbdWbm5tbfpcuhBAFWoEJ+mHDhnHp0iU2bNjwUu1MnDiR6Oho9RYSEpJHFQohROGk1zH6NMOHD2f79u0cOXIEV1dXdbqzszNJSUlERUXp9OojIiJwdnbOtC1zc3PMzc3zu2QhhCg09NqjVxSF4cOH8/vvv3PgwAHc3d115teuXRtTU1P279+vTrt27RrBwcF4eXm96nKFEKJQ0muPftiwYaxfv54//viDokWLquPutra2WFpaYmtry4ABAxg7diz29vbY2NgwYsQIvLy85IobIYTIJr0G/dKlSwFo2rSpzvSVK1fSt29fABYsWICRkRGdO3cmMTGRli1bsmTJkldcqRBCFF56DXpFUV64jIWFBYsXL2bx4sWvoCIhhDA8BeaqGyGEEPlDgl4IIQycBL0QQhg4CXohhDBwEvRCCGHgJOiFEMLASdALIYSBk6AXQggDJ0EvhBAGToJeCCEMnAS9EEIYOAl6IYQwcBL0Qghh4CTohRDCwEnQCyGEgZOgF0IIAydBL4QQBk6CXgghDJwEvRBCGDgJeiGEMHAS9EIIYeAk6IUQwsBJ0AshhIGToBdCCAOn16A/cuQI7733HqVKlUKj0eDn56czX1EUJk+eTMmSJbG0tMTb25vAwED9FCuEEIWUXoM+NjaWmjVrsnjx4kznz507l0WLFrFs2TJOnjyJlZUVLVu2JCEh4RVXKoQQhZeJPh+8devWtG7dOtN5iqKwcOFCvvzyS9q3bw/AmjVrcHJyws/Pj27dur3KUoUQotAqsGP0t27dIjw8HG9vb3Wara0t9evX58SJE1mul5iYSExMjM5NCCFeZwU26MPDwwFwcnLSme7k5KTOy8ysWbOwtbVVb25ubvlapxBCFHQFNuhza+LEiURHR6u3kJAQfZckhBB6VWCD3tnZGYCIiAid6REREeq8zJibm2NjY6NzE0KI11mBDXp3d3ecnZ3Zv3+/Oi0mJoaTJ0/i5eWlx8qEEKJw0etVN0+ePOHGjRvq/Vu3bnHu3Dns7e0pXbo0o0ePZubMmVSsWBF3d3cmTZpEqVKl6NChg/6KFkKIQkavQX/69GmaNWum3h87diwAffr0YdWqVXz22WfExsYyaNAgoqKiaNy4Mbt27cLCwkJfJQshRKGj16Bv2rQpiqJkOV+j0TB9+nSmT5/+CqsSQgjDUmDH6IUQQuQNCXohhDBwEvRCCGHgJOiFEMLASdALIYSB0+tVNwWOokByXN61l5Sa7u84wDjv2jYtAhpN3rUnRAGmKApKfHyet6tN16Y2H9rXWFqiKQDvUwn6NIoCP7eEkJN52KY5sPLp399UAE1i3rXt1gD67yrQYa8oCvEpL//miUtOTfd3PGhe7gPT0qRgvPmyI68DLj+DLb9CTVEUbvfoSfzZs3nednqBjRrneZuWtWpR5pd1en+9SdCnSY7L25AHimgSCbLokadtqkL8n9ZsZpU/7b8kRVHovbM35+6fe/m2tKbADACabmqCxij5pdp7s8SbrG61Wu9vvhfJ74DL62DLr1BT4uPzPeTzS3xAAEp8PJoiRfRahwR9ZsbdADM9PDGKAskv6GUlx8G3NZ7+nZSNYSY9DfHEp8TnScgDaIySKeo5IU/aAjh77yzxKfEUMdXvm+9FClvAvYpQq3jsKEaWlvnWfl7RxsfnyxFCbknQZ8asyKvvKedm6MinwouXKQBDPIe6HsLSRP9vzviUeJpuaqrvMnJF3wGnKApKFj/hqY2P51/vFurfWcmLoR0jS0uM9Nw7Lowk6AuKfBg6AgrEEI+liWWB7z0XdPoMOEVRCM7mENLzerEFZbz6dSRBXxDlxdBRUlz2evxCvEBeDSEVlPHq15EEfUGkj6EjIbIhN0NIBW28+nX0+gV9VtfKpz+xmdlJTrluXYjXbow8t5e35tVlrHl1yerrFfTZPeGZ2ZBHATipWRBk99r49Mvk5Fr6vLjGPasas1NTfl1jn5vAyIuwKCj/YacwyqvLW1/maCavzmu8XkH/Mic8C8BJTX3L7bXxObnS5WWvcc9ujVnVlB/X2OdFYOQ2LOQEaO4VhMtb4wMCSH34UB0uy+0H9+sV9Oll94SnnNRU5eW18Vl52WvcX7bG/LjGXp+BUdhOgGZ25POiI5tXcdSSn5e3KopCcL/+JFy4kOn89B/yaR/cOfX6Br2c8HwpeX1tfH5c456TGl/VNfb5FRjPXuf+vGvbC+pwTnaOfDI7ssnpUUt2h9FyOlyW2/2qjYvLMuSflfbBnVOvb9Bn5dmTtc87Sfsan6AtDNfGP1tjbs4vPNteQfwPPy+6zv3ZcCyowzm5PfLJyVFLbofRsjN0lhf7NauOwMteuSRBn96LTtY+O4RTEE7Q5vYqItDLB5W+TpTm5PzCy4zf53ToIS961zkNyMIwnJOdI5/chF9+DqPlxX7Nr6uaXp+gT4oFo3SbmxSXMehyerL2ZU7QZvfI4Xlh/DJXEcELP6ieDeXnhXF2QlifJ0rz4vzCi8bvczP0kNe96+cFZGG6nv1VXMaZV8NohWG/vj5BP68ymKd7M/lUeH7QZXayNu1Lx7L6YrHs9pBzcuTwvBpf9msTQvwh9sF/25mu/heF8rNhXMOxBj96/6gGVmbBX1BOlOb0/EJ2x+9z01t89qoKeLlefkG6zj3t6CazI5qX2cbntZuTtnO6r7Iztp/VuP7Lbm/6dhVFyXEbr0/QZ+bZHvmzOzB9cGcVztkN5fRyEtBZHTUoiu6HzKgLT+s1tcz4+IoCa9rD3dMZ28+i/pyG8oX7F2jwawP1/ot6388LW0VRSEj978RifEo8rbe0Vv9Ok92hnMyGi5637vPG8jObnllb6XuLObmqAvJnDP3ZsNDGx2cZPs8GWm6GnrI6uknb1txu44vafZm2c/O4z8qqZ59VTZk9L/Dffs3scYP7D8D+xx9yVP/rFfRpvfTMLplMC8M0z/b4sxPO6XvIWfXuMwvoIg66yyoKxEVmPGpIazOzD520ZTP7sEmKzTzkM6s/kw+VtFDOyZUpL+p9Z3UyNydHEumPIrIK7szaa7qpqbpuEdMiOuvl9EgmrY61rdbqTEvfW8zJVRXwXy/f2N4+W+cDXtRjziwsAhs1zjR8XhRoGT6U3qiJ24oVGBV5Zj++4Ojm2W18UeBlt93M2k6/bTk5ukj/gad9ybH9zGrK6nmBp/u19Pr1kJCQ4XETzp/P8ZU3hSLoFy9ezDfffEN4eDg1a9bku+++o169ejlvKO2SyvQ997Sx+uS4jGGYFnymRXTDeVzg02mZ9ZLTPkBc60Ivv6eP97yjgm9r6IZzZsuktZm23PM+dNKHddp5gBd9sCTFgk9F3f2RjqWJpRr0aXZ22omliSUWxhY6L9xHiY/U3nf6Q8zMxvufDWdFUXiY8DDbRxLpjyIyC9u0x8msvbR104480pbNzfDShfsX6LWrF2ua/PjCZZ8dF86qtx/YqLEaohqNJmPgvajHnC6AswrHzE4e5vjE7rnzXK9dRw0mIyMjtb405fftxbhYMQCC+/Ql4dKl/7axVi1Kr1tLcM+Pnht4RkZGGYK6wtG/MLK0zHr/pfsge26o5uIDL41F9Wq4Ll369Dmy0H0vPFtXhpqes6/jz53ndvcelP55hc5+TLtkNqcK/I+Db9y4kbFjxzJlyhQCAgKoWbMmLVu25N69e7lrMLOe+8+tdMN/1Hnd5X9uqXsE8Ov/fjXqeb3kO6dglgusaAFa7dNpWQV02pFAWjA/L8STYnWnjbsBE+8+DfD0NafV/XUp3dq/rQFrOzydb/q/I49fu/83P5P9kdbLTd+bbb2lNU03NWXQvkFYGFtgaWLJ4H2D1ZAHGLRv0NNeUSbrN93UlI92fkRsUmyWy6SpVrwaJ7qd4FDXQ5nvF/4L2+eNX+7stDPDtLP3zhKXHEfvnb2pv75+hsev5lCNPzv+yc5OOznU9RD+3f0zrePC/QvEp2T8vvasepHwX08yq95+Woheq1Wb2927o/3f60hRFFIfPnx+j/l/697u+ZHOPql47CgVjv6lU0/a/GdrLb9vLxWPHaXSmdNUDjhDxWNHn/t4t7v3UJ/L4H791Xn/ercgZOAgADXk1fUCAtA+evTCwNNqtdzu0VPniOLOsOFP28xq//2vF53WM8/yMQICSL57l5TISLRxcS9cPr2Ei5e40fgtAhs1JmTAABRFee7zmr6m9Mrv25ux7fPndf5vxMucOC7wQT9//nwGDhxIv379qFKlCsuWLaNIkSL8/PPPuWswy557ukMh03RDF8nxGYP37ind5Uc957D8zilY8W7G8f9xgVCq1n/3M/vAGRcILnV011vTQXcZU0tY1+m/oZu0ZZJis/7ASPsQ+rlV5sM6If6QrvedkJqQZS83LWDjkuMyLPM0/LLuJaf1qvvs6pPp+mkuPbjEJ/s/wcLYQp2WWWhfuH9BZ2z/WenPCaRf/3nbdynyEm1+b6N+sA3ZP+SFdaRJ6xWmD6d/vVtwrVbtp+H9TAhn9mZP87zAs6heXSe8ddYLCNAJC42FBXeGDlPvBzZqzO2eH2Xa7r/eLdQA01ha6gRNlsEUH48SH58h5J6tI6ttzardzD4Mng3CtA8li2rVMmxf+v1c4ehfWNSoodNW2rZm9rxktnxmsvpwrXD0rxfW9KJ9+7IK9NBNUlISZ86cYeLEieo0IyMjvL29OXHiRKbrJCYmkpj4349wR0dHAxCTqEBMzP8W+t8OHnwMljV6+nfM4/+mZ/V3VsvHp6Zb5jgsa6hb1M2/ITJc97FjnsCtM7rL3TgBkfd0l7l5KpO20i0TeQ9u+D9/mRHnnv773RvPf7x02xcX85jU+Kc/yv043d+b39tM522ddZo5G3yW+4/uZ7pMzP/2+fPWP337dJbrZ/UYKXEpmS6fvtZnHzv9vPTrv2j7nldr+nZiYh7zJDXdY8fEcP901kd9T06dwub+fXWdJykp6t/uW//g1vvtdZcPCMA2ODhDm0/OncP2yRN13fJ79wDwb4t3n9by+L+6ou/f58Ezgfnk1ClsMmlXnX8mALuIiKd/v6DWtH2e6bx0daRfP6vpWa2bZZvJyZCczIPz6Y7IM9nPj588ybAPcrN8Zs9Rluu/oKbs7Jtn/4YcXIGjFGB3795VAOX48eM608ePH6/Uq1cv03WmTJmiAHKTm9zkZvC3kJCQbGVpge7R58bEiRMZO3asel+r1fLw4UMcHBwK3H/5FkKI3FAUhcePH1OqVKlsLV+gg7548eIYGxsT8b/DxjQRERE4Oztnuo65uTnm5uY60+zs7PKrRCGE0AtbW9tsL1ugT8aamZlRu3Zt9u/fr07TarXs378fLy8vPVYmhBCFR4Hu0QOMHTuWPn36UKdOHerVq8fChQuJjY2lX79++i5NCCEKhQIf9B9++CH3799n8uTJhIeH88Ybb7Br1y6cnJz0XZoQQhQKGkXJxTfkCCGEKDQK9Bi9EEKIlydBL4QQBk6CXgghDJwEvRBCGDgJ+kLsyJEj3Lx5k48++oiuXbty5MgRfZck8sDevXsZOHAg586dA+DHH1/89cfi1frzzz/5888/2bFjBx07duTPP//Ud0nPVeAvr3wZe/fuxdvbG41GQ0REBPb29qxbt4579+5Ru3Zt6tWrx6pVqyhWrBidOnVixYoVNGvWjOrVqwPwzz//ULVqVQBSUlI4duwYjRo14vjx47i4uFC+fHkSEhL46aefiIuLo3LlytSpUwcXFxcAQkND1f+inNZWfHw8GzZs4N69e7i6utKpUycsLS0ZMWIE0dHRtGnThnXr1tG2bVuGDBkCPP2fwCtWrKBkyZI8efKEChUq8PjxY3777Tesra2ZP38+dnZ29OnTh7fffpuoqCh2795N69at2bx5M+3ateOff/4hMjKSJ0+eEBERgbu7O4mJidy9e1etIzExkYcPH/LkyROqVavG9u3bqVatGsePH9dZztLSkvj4eFasWEFsbKzO9NDQULZs2UK/fv2YP38+tra2DBgwgOrVq9OrVy8+++wzjh8/rj4va9euxdXVlSVLlhAYGIipqSnDhw9n+/btaDQaNm7cmOGrK1JSUtR9e+LECerWrYuFhQV///03ycnJ3LlzB0dHR8LCwrh7967OtpYoUQKA+/fv4+Hhwfvvv6+2u23bNuLj4/Hw8KBGum8rTEhI4Ntvv0Wj0eDq6kqlSpWoVKmSzr59/PgxrVq1wtTUlB07dlCnTh0cHByYNWsWf//9N1FRUdjb2/P555+TlJSkLh8bG0tCQgK2trZs3ryZu3fv4ufnx5YtW5g3bx4PHz7k3LlzXLp0iSdPnpCamsqdO3dwdXWlUaNGXLp0iQMHDjBixIgM++nkyZO4urqqr8c//viDxMRE7O3tiYuL45133mHFihXUrl0bc3NzKlWqxA8//EDfvn1xdHRU27l06RKPHz+mdOnSuLi4EBERQUJCAgcOHODJkyf06NEDBwcHdu3aRatWrQD49ddf+eCDD1i3bp3OMhEREZw6dYr79+9z6NAhYmJiKFKkCIqiUKlSJTw9PXF1dSUuLk59jQQGBlKx4tPfS4iKiuLGjRtUqlQJPz8/3njjDfW5Cg0N5eHDhxn2R2hoKKdPn8bLywsfHx969OjB7du3qVu3LiVLlsywfenf0+lfI4GBgRQtWhRnZ2emTJnChx9+iKOjI48ePSI8PJyVK1fy8OFD6tatS+PGjdm+fbv6GPD0Cxfj4+OJiIjg8ePHVKpUiT/++INWrVrh6OjIpUuXuHXrFoqiqM9NWh79/fff6m9wpN/P2WXQl1fWqlULV1dXatWqRUhICCVLlqRhw4bMmTOH+Ph4nJ2diYiIwMzMDFNTUwYMGMCaNWtYsGABiqIwfvx4fHx8ABg/fjz//vsvtWrV4saNG8TFxfH222+jKAo3b97Ew8ODgIAAnjx5gpeXF4MHD+brr79m8uTJzJ07lwMHDtCvXz9u377N/fv3mTNnDj169ODx48fUqVNHffLi4uLYsWMH5cuXp3bt2gCcPXuWyMhI1q1bx7p167h+/TrVq1fnwIEDmJubc/36dS5fvsy0adOYMmUKI0aM4NGjR7i6uqIoCnfu3GHgwIH4+fmRmppKtWrVOH36NMWLF+err75i3rx5/Pvvv5QqVYrTp0/j5uaGra0tXbt25YsvvmDJkiWULl2a69ev4+fnx7Jlyxg0aBAPHjzAx8eHo0ePsmfPHmbOnMmoUaOIjY3FwsICrVZLQkICRYoUwdramsjISFxdXdm/fz+enp6888473L59GwcHB3x8fPj444+xsrLin3/+Yd++fTg6OuLl5UWtWrW4e/cuMTExeHh4EBgYyOXLl6lSpYoagLVr12bv3r2UK1eO6dOn880332BhYYGHh4fOtk6YMIHY2Fhq1KiBh4cHFy9exMfHh4kTJ+Lv70+VKlVwc3MjMjKSYcOefp3vjBkzCA4Opk6dOvz1119YW1tjZ2ens2+///57EhISqF27Nrt376ZkyZLUrl2boKAgqlSpgr29PSkpKRw8eJCBAwfy119/ERoaSsmSJSlWrBjHjh1j9uzZlC5dmnHjxlGqVCl+/vln6tevT2hoKF27duXYsWOYmJgwYcIEvv32W2JjY/Hy8mLDhg2YmJjQr18/Tp06hZWVFYqisGfPHpycnPD29sbCwoITJ07g4eGBv78/VatW5eHDh8ycOZMuXbowfvx4Dhw4wKlTpzA1NWX69OlcuHABFxcXQkNDOXLkCAkJCbz11luYmJhw7NgxZsyYwZdffqmG244dO3BwcKBBgwbs27ePkiVL4uPjQ7FixejYsSNvv/02Z8+e5eHDh1SpUgUHBwfs7OxYtWoVQ4YM4fLly4wfP57g4GCmTJmiPverV6/mjTfeoH379mzZsoXmzZurHzJhYWE0a9aMIkWKcPz48Qz7o3///owZM4YuXbowatQoOnXqxNatW/nmm2+YNm0agwYNyrB96d/T6V8jNWrUICUlhalTp/Lee++xaNEiqlSpwpw5c2jTpg0NGzZk/vz5PHr0CDc3N5KSkrh48SL9+/enSJEi7NmzB0dHR06ePEn58uUpUqQIvXr1YurUqfTv35/Q0FB2796Nk5OT+q2UgYGBNGjQQGffXrhwgZo1a7Jp06ZsZ6FB9+jr16/P0qVLOXXqFP369SMlJYXp06fz+++/Y2pqipGREY6Ojmq4zJ8/HyMjI3x9fQE4fPgwv/32G4qiEBoaio2NDTY2NtSqVQszMzOGDRtGhw4daNSoEYqiUK1aNYyMjBg5ciSNGjWiTJky+Pr6cunSJZydnWnRogVDhw6lUaNGVKtWjdGjR7N8+XLWr19P7dq18fX1Zdu2bQBYWFioT+SIESM4duwYrVq1Yvv27dSrVw9zc3P1QwmgV69eVKpUCV9fX6KiojAxMaF06dJoNBpCQ0MZOnQo58+fx9LSEq1WS9WqVTE1NaVatWpYWFhw//59jhw5wqBBgzAyMiI4OJgePXrw1Vdf0aZNGwA6d+6MkZERw4YN49SpUxgZGVGtWjX69OmDsbExvr6+REZGYmJigkajoXz58piZmXH9+nVcXFxwcXFh6dKl9OrVi/Lly9O2bVs++eQTHj58SOXKlblw4QJWVlZoNBqOHj2KjY0NW7du5dSpU/Tu3ZuqVavSokULNm/erL4he/bsyf79+/H19eWNN94gICAAgO3bt6sfNum31dXVVf21ooULF6rbc+LECTQaDXZ2dkyfPh1HR0f1DRcYGKiuU7t2bczMzJ7+olC6fWthYcHKlStZv349b7zxBv/88w+DBw/Gzc2NqKgoLNP9fuzQoUO5ePEiFy9e5PDhwwB4enqq+3nIkCHs3r0beNpZMTU1Zd68eYwYMYLU1FTatWvHjh07OHr0KPPmzSMuLg6NRkPbtm3ZuXMn9+7d49SpU9SoUYMLFy5w9epVOnXqRMOGDSlatCgNGzbE3NycR48e0bBhQ2xsbBg9ejQ3btzAxcUFIyMjrKys8PPzw9LSUt0WIyMjNSxNTExo1aoV4eHh6mu4bdu2tGjRgtGjR1O3bl1at25Nq1atMDIyokqVKtStWxdHR0f+/vtvDh8+TP/+/bl//z4XLlzgzp07lC9fnnbt2gGwbNky9bnftGkTGo0GKysrLl68iKurK6VLlyYlJYVq1aoxdOhQOnbsCJBhf3z11VcEBASwefNmPv30U5YuXcqOHTvo0aMHX3/9NYGBgSxbtkxn+9K/p9O/RkxMTDAxMcHKyopBgwbh5OSEg4MDxsbGpKam0qpVK/z8/DAxMSEoKAg3Nzfc3d1p0aIFw4cPJzExkf379zNw4ECMjY0xMTGhS5cuTJ8+Xa0jKioKCwsLrl69yrvvvotGo8HX15d3331X3befffaZ+r7PLoMO+rQv/albty4//PADPj4+eHp6YmJiwrRp0+jQoQNz5sxh/fr1jB49moULF9K+fXumTJkCwLVr15g8eTIA8fHxVKlShVatWjFhwgRMTU2pXLkyTZo0YfXq1SxfvpwDBw5Qs2ZNKleuTP/+/fnll1+YMmUKQUFBNGvWjMaNG/P+++8zb948Hj16BED37t0ZM2YMbm5uALz33nsATJo0Sd2Obt26ERwcjKenJ0lJSeobokmTJur3AH300UeMGTMGgCJFiuDk5ESPHj3YuXMnO3bsoHHjxkRGRmJmZsb48eMxNjZm7ty5dOvWjb1796qHlxYWFmzbto1evXrx8ccf4+TkxIcffohGo8HExIRJkybRrVs3fv31V3V9rVbL+PHj6datGyYmJuzYsYNu3bqpH5xjxoxh1apVvP322wC4uLgwdepUAM6cOcOGDRsIDg6mV69euLq60qRJE1auXEmzZs3U569BgwZ89913WFtbU6NGDfz8/Dh37hxOTk6cPn2aUaNGYWpqSq9evXB0dOT48eMAfPbZZ+q2fvjhh1y6dAkrKytGjhyJjY0Njo6OjBo1isGDB3Pu3DnKlCkDwJtvvqk+9ykpKezcuZN69eoRFhaGmZkZQ4cOZdeuXeq+LVWqFO+88w5jx45Ve2PTpk3j4cOHDBw4kKVLl+Lv78+FCxdo3LgxV65coXjx4upz7OjoSNeuXdUPkA4dOgBw+/Zt9blxd3dn8eLFjB07lq1bt6rDK7a2toSHh1O3bl1OnjzJgQMHGDVqFPH/+7UoDw8Pqlevzvr16/n666+JjY1lw4YNjBw5kvbt26vDiwsWLGDkyJEULVqULl26sHLlSrW+pKQkFEWhcuXKTJgwgUGDBuHp6Ymnp6f62nNwcOCDDz5gzJgxFC9enBs3bqjLDB06lNq1azNu3DgiIiLw9PSkYsWKlC9fnj///BMbGxvi4+MZO3Ys9+7dU7etbt26NGnShG+++QZra2uCgoL44IMPcHV15ZNPPsHOzg4PDw8cHR05derpbzfY2dkRFhZG3bp1qVu3LlOmTKFnz554eHjg6upKmTJlGDBgADExMURGRgKQnJxMamoqlStX5u2332b16tX89NNPOq+RIUOGUKlSJbp06cIHH3xAUFAQ7u7uWFpasnDhQjw8PEhNTaVkyZI0a9aMjRs30rRpUxo3bkxiYiI3b94EoFKlSly6dImffvoJgLi4OLWOcuXKsWLFCr744gu2bduGq6sro0ePplSpUnzwwQeMHTuWBw8eZB16WTDooC9WrBjdu3enVatWLF68GHd3d6pXr05YWBgzZszg22+/5fLlywwcOJAePXpgb2/PmjVreOuttyhevDjjx49X22rTpg3bt29nz549XLlyBXt7ezZs2IC/vz+ffPIJf/zxByYmJpiZmQFw7Ngx6tWrR2xsLM2bN8fBwYEdO3awc+dOtfd06NAhjI2NWbZsWYafRuzWrZv69+eff06fPn345ZdfOH78OBs2bKBp06YAuLq6Ak/fiGnb6uvrS7ly5di2bRv37t2jZcuWNG7cmOHDh9OrVy86duzI2rVrqVatGm3atOHff/9VD73Pnj3LiBEjCAgIICIigooVKxIdHa323g4cOMD27du5efMmVlZW3LlzB61Wy+rVT393dcOGDRQpUoSiRYtibm5O06ZN2b17N66uruqHWd26dWnfvj0PHz5U93P37t11tv/TTz/Vuf/+++8zffp0QkNDuXv3LlWqVCEsLIyLFy9y9+5dxo4dS8WKFXn06BGHDx/G2NgYR0dHTExMGDp0KK1bt+bHH3/k+++/5+zZs6SmpnLo0CGcnZ2pWLEi58+fp1GjRlSsWJGOHTtSo0YNDh48yJIlSwgLCyM5OZkffvhBrdfU1BQLCwvs7e3x8fHh9u3bzJo1Sx2mSutU/PTTT3z++ec4Ojpia2vL8uXLGTp0KJ6entjZ2XHu3DneeOMN2rRpw4QJE9TtnTNnDoA6nPjWW2+h1Wrx9PSkS5culC9fnrVr17JhwwZ27NhBkSJF2LBhA/Pnz1d70wcPHqRBgwaYmpqqvdMjR45w4cIFSpQogZmZGWZmZly9epXly5fTo0cPPvjgA9zd3fnoo4/Ucx2rV6/m1KlTpKSksHr1ar799lvc3d2ZNGkS06dP5+7duwwZMoTFixfTrl07vvzyS06cOMH9+/fVwC5VqhTu7u7UrVuXxMRE9QjHwsKCCRMm8Oeff5Kamkp0dLR6VJS2/x88eECrVq34/vvvKVq0KD169GDUqFEEBATQtGlTunTpQlJSEp988gldunTh0KFDvPvuu8TGxmJlZcW0adOAp+fsNm7ciJWVFZMnT8bX15fBgwcDcPXqVZydnYmNjeWHH35g2bJlaDQa9u7dy//93//RtGlT3nvvPbXj9NNPPzFw4EDc3d1p1KgRjRo9/cGeP//8E19fXxo0aMCff/7J7du3OXfuHMuWLeP333/no48+4sKFC9jZ2bF+/Xq2b99OQkKCWm/ah/Lq1atRFIWPPvqIjRs3cuXKFf744w9CQ0PRaDQsXbpUPYeXHQYd9IGBgfz66694e3vToEEDjhw5wrlz59TDMHNzcypXroy/vz/9+/fn0qVLrFixgi1btjB79mzc3d2pX78+8LTnef/+fW7cuMHQoUMxMTFh7dq1vP322xw6dIhz587RtWtX5s+fz8GDBwkLC+PmzZv079+fgwcP8uGHH1KnTh0ePHjAuXPn2LlzJwMHDiQsLIyPP/4YOzs7+vXrR4MGDTJsh6enJyVKlGDAgAGcOXOGpUuXsm7dOvVE3fO2tW7duly6dIkGDRpgZWWFkZER/fv35/Tp06xbt46ZM2cCT88D1K9fn6CgIPz8/Ni8eTO2trZ4enry77//4u3tjaenJ4cOHeLw4cNMnjyZ6OhoSpcuzc2bNzE3N2ft2rV4enpib2+fYd8AjBo1CoADBw7wxx9/8NlnnzF79mz69OlDw4YNM2x3165d1b/T7/8RI0aQkpLCunXrCAgIwNPTk82bN3P9+nUCAwM5cuQIQ4YMUZ+jzp07ExISQv/+/Tl//jyrVq3iyy+/JDExkdDQUO7fv8/ly5cpU6YMDx48IC4ujgv/+yk8X19fndfLrVu36N69O/Xr18ff3x8TExN+++03AgMDadiwIdbW1hw8eJBff/2VkSNHEhcXpx69/frrryQmJvLrr78yfPhwdRsePnzITz/9pA47KYrCuXPn+Pzzz3X2VXBwMIqisHnzZk6fPs2bb76ZYZ8rikJAQAD16tUjKiqKcePGcenSJWJiYpg7dy4nTpzg888/Jz4+nrVr17Jv3z6qVKlCiRIl6N+/PxcvXqRcuXL8/PPPTJgwQV2ufv36mJmZsXbtWipUqICDgwPr1q2jUaNGmJqasn79esqXL69e8NCgQQNSU1OxtbVl1qxZ6nvp9OnT1K5dmx07dhAXF8fQoUMBdE5upqamcvHiRXXYonv37tja2rJu3TpOnz7NG2+8keH1NXLkSI4cOUJAQID6vurfvz92dnbcuHEDBwcH/P39efPNN9m8eTPt27fHx8eHAwcOAOi8X0+fPk3ZsmXVddJeR9u3b8fe3p46deoQFxen9qzTv0737duHkZERTZs2JTQ0lI8//ph169YRGBjI9evXOXz4sM5+fXb/p8+gmJgYJk6cyIkTJ5g6dSrLli3j6tWrOu+l7DLoyysjIyNZv349Wq2W6OhooqKiWL58OWfPnuXmzZvEx8erQzAbN26kXLly/Pjjj8THx2NkZISlpSWbNm1i06ZNuLi4UKxYMUqUKIGjoyN2dnYMHjwYGxsbkpKSWL58OZGRkTRp0oRNmzbRsmVLOnTowMaNGzl69CgXLlzAwsICZ2dnnJycWL58Obdv38bZ2ZmNGzfy5ZdfsmvXrky3w8TEhPbt27Nx40bq1avHsWPH8PHxYc+ePerhalbbOnr0aPXkqIODAwsXLmTjxo00bNiQ3bt3M3jwYA4fPoxWq8XCwgJFUShatCiOjo6YmZmh1WrVdk+cOEFUVBQlSpTg0aNHxMfHExcXR/HixbGysmLw4ME4ODhgbm6eYd/89ttvxMY+/WHzBw8ecOzYMXU/FylSJNPttrGxyXT/29ra4ujoiI+PDw8fPuTChQv4+Phw9uxZwsLCcHR01HmOTExM1Oe4bNmyfPPNN2i1WmbNmqWOifbu3ZvKlStjYWFB1apVqVevHg8ePMjwerG1taVVq1Zs2rSJVq1a0bJlS3x8fLh+/ToHDhwgPj5eHXdPa6t3797A0yuvIiIi1N592jbs2bOH6OhodVt9fX3x9vbOsK9sbGyws7PDx8eH6OhoTp8+nWGfp38uLS0tKV++PPHx8Vy+fJmkpCT1KpF79+6h1Wo5evQoiYmJ6uuraNGiXL9+XX2O05a7fv06Z86cQavVkpSUxIMHDxg8eDCRkZHcunVLnR4ZGcngwYN58OABkZGRxMXF6byXatasSceOHSlWrBhHjx7l/v37wNPzYY8fP850/9+/f5+UlJQM253+9XX37l2ePHmS6fvq0aNH6vP1xx9/0K1btwz7PP37tV69erz11lsZnuO2bdsSFBSU4XlN/zq9c+cOZcuWxcLCguLFizNkyBB8fHwICAggLCwsw359dv+nz6D0z1mxYsVQFCXDeynbsvU7VIVUcHCwsmPHDiUyMlL55ptvlG+//VaZPXu2MnfuXGX27NnKvXv3lL/++ksJCgpSFEVRLl++rMybN0+5d++eoiiK8tdff6ltHTp0SNm2bZuiKIpy5coVZcuWLYqiKIpWq1VmzJihzJ49W1mwYIESFxenrhsZGalTz969e5UvvvhC+f3335XZs2crkydPVpd/nvR1+Pn56cxbtGjRc7f1l19+UeLi4pS9e/cqvXv3Vte7cuWKTjuHDh1S9u7dq3z00UfK4cOH1ek//vij2u6QIUOUVatWqfuqb9++yr1795QrV66o+/DKlSvKoUOHMuybtDoy289p6z7r5s2bOvWl7X8/Pz91//v5+an74NChQ8rIkSPVOtKW+euvv9Sa0u8nHx8f5dKlS8revXuV//u//1MURVH/1mq16vOU/vVy8+ZNtV4/Pz/1Ob58+bLSoUMHnW1K325afWn7Nv02KMrTn8BML327afvKz89PZz+nbXf6fZ7+ufzkk0/UdQ8dOqRs3LhR3Qf/93//p+6DNWvWZFpj+uW+/PJLZcmSJUpkZKTy2WefKZcuXVKXmT17dobply9fVoYOHZrhvZS2/2/cuKHu//Qy2/9jxoxRXzvptzv962vdunXKhg0bMn1fpb2O0t47afs2/T5P/35N/7pL/xwrytP327PPa/rl09rfu3ev8sEHH+js17TX5vP2f/rnO/1zptVqlc8//zzDeym7DPrySiGEEAY+dCOEEEKCXgghDJ4EvRBCGDgJeiGEMHAS9EIUIFOnTuWNN97QdxnCwEjQi0Knb9++6lcFmJqa4uTkRIsWLfj555/RarU5amvVqlXY2dnlT6G5MG7cOPVrLbKrbNmyLFy4MH8KEgZBgl4USq1atSIsLIygoCB27txJs2bNGDVqFO3atSMlJUXf5eWatbU1Dg4O+i5DGBgJelEomZub4+zsjIuLC7Vq1eKLL77gjz/+YOfOnaxatUpdbv78+VSvXh0rKyvc3NwYOnQoT548AeDQoUP069eP6Oho9Qgh7cvW1q5dS506ddTvH+/Ro0eG7yN6VtmyZZkxYwbdu3fHysoKFxcXFi9erLNMcHAw7du3x9raGhsbG7p27UpERIQ6/9mhm759+9KhQwd8fHwoWbIkDg4ODBs2jOTkZACaNm3K7du3GTNmjLoN8PTL0N577z2KFSuGlZUVVatWLfA/jiHyjwS9MBjNmzenZs2abNmyRZ1mZGTEokWL+Oeff1i9ejUHDhzgs88+A6Bhw4YsXLgQGxsbwsLCCAsLY9y4ccDTbzOcMWMG58+fx8/Pj6CgIPr27fvCGr755htq1qzJ2bNnmTBhAqNGjWLv3r0AaLVa9cvcDh8+zN69e7l58yYffvjhc9s8ePAg//77LwcPHmT16tWsWrVK/TDbsmULrq6uTJ8+Xd0GgGHDhpGYmMiRI0e4ePEic+bMwdraOqe7VBiKHP0/WiEKgD59+ijt27fPdN6HH36oeHp6Zrmur6+v4uDgoN5fuXKlYmtr+8LHPHXqlAIojx8/znKZMmXKKK1atcpQT+vWrRVFUZQ9e/YoxsbGSnBwsDr/n3/+UQDl77//VhTl6X/Lr1mzpjq/T58+SpkyZZSUlBR1WpcuXZQPP/xQ53EXLFig87jVq1dXpk6d+sLtEq8H6dELg6Iois5P6u3bt4933nkHFxcXihYtSq9evdQv23qeM2fO8N5771G6dGmKFi1KkyZNgKdDL8/j5eWV4f6VK1cAuHLlCm5uburXNQNUqVIFOzs7dZnMVK1aFWNjY/V+yZIlXziMNHLkSGbOnEmjRo2YMmWK+m2c4vUkQS8MypUrV3B3dwcgKCiIdu3aUaNGDTZv3syZM2fUMfOkpKQs24iNjaVly5bY2Njwyy+/cOrUKX7//fcXrpdfTE1Nde5rNJoXXl308ccfc/PmTXr16sXFixepU6cO3333XX6WKQowCXphMA4cOMDFixfp3LkzgPq1uvPmzaNBgwZUqlSJ0NBQnXXMzMxITU3VmXb16lUiIyOZPXs2b731Fh4eHi/sQafx9/fPcN/T0xN4+rsCISEhhISEqPMvX75MVFQUVapUyfH2Pm8bANzc3Bg8eDBbtmzh008/Zfny5bl+DFG4SdCLQikxMZHw8HDu3r1LQEAAX3/9Ne3bt6ddu3bq94RXqFCB5ORkvvvuO27evMnatWtZtmyZTjtly5blyZMn7N+/X/3RkdKlS2NmZqaut3XrVmbMmJGtuo4dO8bcuXO5fv06ixcvxtfXV/2RCG9vb6pXr07Pnj0JCAjg77//pnfv3jRp0oQ6derkel+ULVuWI0eOcPfuXfXHMEaPHs3u3bu5desWAQEBHDx4UP3AEa8hfZ8kECKn+vTpowAKoJiYmCiOjo6Kt7e38vPPPyupqak6y86fP18pWbKkYmlpqbRs2VJZs2aNAiiPHj1Slxk8eLDi4OCgAOp3lK9fv14pW7asYm5urnh5eSlbt25VAOXs2bNZ1lWmTBll2rRpSpcuXZQiRYoozs7OyrfffquzzO3bt5X3339fsbKyUooWLap06dJFCQ8PV+dndjL22RPPo0aNUpo0aaLeP3HihFKjRg3F3NxcSXtLDx8+XClfvrxibm6uODo6Kr169VIePHjw4p0rDJJ8H70QeaRs2bKMHj2a0aNH67sUIXTI0I0QQhg4CXohhDBwMnQjhBAGTnr0Qghh4CTohRDCwEnQCyGEgZOgF0IIAydBL4QQBk6CXgghDJwEvRBCGDgJeiGEMHD/D6NfotOTgh85AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 400x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import matplotlib.pyplot as plt\n",
        "import scipy.cluster.hierarchy as sch\n",
        "\n",
        "# Generate random dataset\n",
        "X, y = make_blobs(n_samples=100, centers=4, random_state=42)\n",
        "\n",
        "# Fit hierarchical clustering model to data\n",
        "hc = AgglomerativeClustering(n_clusters=None, linkage='ward', distance_threshold=0)\n",
        "hc.fit(X)\n",
        "\n",
        "# Plot dendrogram\n",
        "plt.figure(figsize=(4, 4))\n",
        "dendrogram = sch.dendrogram(sch.linkage(X, method='ward'))\n",
        "plt.title(\"Dendrogram\")\n",
        "plt.xlabel(\"Data points\")\n",
        "plt.ylabel(\"Distance\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f3e77ed3",
      "metadata": {
        "id": "f3e77ed3"
      },
      "source": [
        "### DBSCAN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e4a1db83",
      "metadata": {
        "id": "e4a1db83"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import make_moons\n",
        "from sklearn.cluster import DBSCAN\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Generate moon-shaped dataset\n",
        "X, y = make_moons(n_samples=200, noise=0.05, random_state=42)\n",
        "\n",
        "# Fit DBSCAN model to data\n",
        "dbscan = DBSCAN(eps=0.2, min_samples=5)\n",
        "dbscan.fit(X)\n",
        "\n",
        "# Get cluster labels and number of clusters\n",
        "labels = dbscan.labels_\n",
        "n_clusters = len(set(labels)) - (1 if -1 in labels else 0)\n",
        "\n",
        "# Plot clusters\n",
        "plt.figure(figsize=(4, 4))\n",
        "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis')\n",
        "plt.title(f\"DBSCAN: {n_clusters} clusters\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7aa4252",
      "metadata": {
        "id": "a7aa4252"
      },
      "source": [
        "## 4. 차원축소"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "761e086c",
      "metadata": {
        "id": "761e086c"
      },
      "source": [
        "1. 주성분 분석(PCA)\n",
        "- 특징\n",
        "    - PCA는 고차원 데이터에서 분산이 최대가 되는 방향을 찾아 원래 분산을 최대한 유지하면서 데이터를 저차원 공간에 투영하는 선형 차원 축소 방법입니다. \n",
        "    - 데이터 압축, 시각화 및 기능 추출에 널리 사용됩니다.\n",
        "- 장점:\n",
        "    - PCA는 계산 효율적이고 해석 가능하며 대규모 데이터 세트를 처리할 수 있습니다. \n",
        "    - 또한 광범위하게 적용 가능하며 다양한 도메인에서 사용할 수 있습니다.\n",
        "- 단점: \n",
        "    - PCA는 데이터가 선형적으로 분리 가능하다고 가정하고 데이터가 복잡한 비선형 구조를 가진 경우 제대로 작동하지 않을 수 있습니다.\n",
        "\n",
        "2. t-분산 확률적 이웃 임베딩(t-SNE)\n",
        "- 특징: \n",
        "    - t-SNE는 고차원 공간과 저차원 공간의 점들 간의 쌍 유사도를 나타내는 확률 분포를 최적화하여 고차원 데이터를 저차원 공간으로 매핑하는 비선형 차원 축소 방법입니다. \n",
        "    - 일반적으로 데이터 시각화에 사용됩니다.\n",
        "- 강점: \n",
        "    - t-SNE는 데이터의 로컬 구조를 보존하는 데 효과적이며 데이터의 포인트 간의 비선형 관계를 밝힐 수 있습니다. \n",
        "    - 또한 고차원 데이터를 시각화하는 데에도 적합합니다.\n",
        "- 약점: \n",
        "    - t-SNE는 계산 비용이 많이 들고 하이퍼파라미터에 민감하며 구성 요소 수가 너무 적으면 과적합될 수 있습니다.\n",
        "- 매개변수: \n",
        "    - 주요 하이퍼 매개변수는 데이터의 로컬 및 글로벌 구조 보존과 유지할 구성 요소 수 사이의 균형을 제어하는 ​​perplexity입니다.\n",
        "    \n",
        "3. 선형 판별 분석(LDA)\n",
        "\n",
        "- 특성: \n",
        "    - LDA는 데이터에서 클래스 간의 분리를 최대화하는 방향을 찾는 것을 목표로 하는 감독된 차원 감소 방법입니다. \n",
        "    - 일반적으로 특징 추출 및 분류에 사용됩니다.\n",
        "- 장점: \n",
        "    - LDA는 클래스 분리성을 유지하면서 데이터의 차원을 줄이는 데 효과적입니다. \n",
        "    - 또한 분류 모델의 성능을 향상시킬 수 있습니다.\n",
        "- 약점: \n",
        "    - LDA는 데이터가 정상적으로 분포되고 클래스 공분산이 동일하다고 가정하므로 실제로는 그렇지 않을 수 있습니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c7b2fdf",
      "metadata": {
        "id": "4c7b2fdf"
      },
      "outputs": [],
      "source": [
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_dataset()\n",
        "\n",
        "# Initialize LDA with n_components=2\n",
        "lda = LinearDiscriminantAnalysis(n_components=2)\n",
        "\n",
        "# Fit and transform data\n",
        "X_lda = lda.fit_transform(X, y)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
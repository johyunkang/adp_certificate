## 4과목 데이터 분석 (40)

## ADP 데이터 분석 START

### 1장 통계분석

### 1절 통계분석

#### 1. 확률 분포 (p.66)

##### 가. 이산형 확률분포

- 확률 변수가 가질 수 있는 값이 명확하고 셀 수 있는 경우의 분포, 확률값은 확률질량함수를 이용하여 계산

> $P(X_i) > 0$      $  i=1,2,...,k$      $\displaystyle \sum_{i=1}^kP(X_i)=1$

###### 1) 베르누이  확률분포(Bernoulli distribution)

- 결과가 2개만 나오는 경우 (ex. 동전 던지기, 시험의 합/불합격 등)

> $P(X=x)=p^x(1-p)^{1-x}$  (x=1 or 0), E(x) = p,  var(x)=p(1-p)
>
> 예) 메이저리거인 추추가 안타를 칠 확률은 베르누이 분포를 따름. (안타를 치는 사건을 x=1이라고 할 때 안타를 칠 확률은 타율로 적용 가능)



###### 2) 이항분포(Binomial distribution)

- 베르누이 시행을 n번 반복했을 때 k번 성공할 확률



###### 3) 기하분포(Geometric distribution)

- 성공확률이 p인 베르누이 시행에서 첫번째 성공이 있기까지 x번 실패할 확률



###### 4) 다항분포(Multinomial distribution)

- 이항분포를 확장한 것으로 세가지 이상의 결과를 가지는 반복 시행에서 발생하는 확률 분포



###### 5) 포아송분포 (Poisson distribution)

- 시간과 공간 내에서 발생하는 사건의 발생횟수에 대한 확률분포 (예. 가게에 손님이 1시간에 20명씩 방문한다고 할 때, 10분에 손님이 5명씩 방문할 확률)



##### 나. 연속형 확률분포

- 확률 변수가 가질 수 있는 값이 연속적인 실수여서 셀 수 없는 경우의 분포이며, 확률값은 확률밀도함수를 이용하여 계산한다.

###### 1) 균일분포 (일양분포, Uniform distribution)

- 모든 확률변수 X가 균일한 확률을 가지는 확률분포 (다트의 확률분포)



###### 2) 정규분포 (Normal distribution)

- 평균이 &mu;이고, 표준편차가 &sigma;인 X의 확률밀도함수
- 표준편차가 클 경우 퍼져보이는 그래프가 나타난다.



###### 3) 지수분포 (Exponential distribution)

- 어떤 사건이 발생할 때까지 경과한 시간에 대한 연속확률분포이다. (예. 전자렌지의 수명시간, 은행에 고객이 내방하는데 걸리는 시간, 정류소에서 버스가 올 때까지의 시간)



###### 4) t-분포 (t-distiribution)

- 표준정규분포와 같이 평균이 0을 중심으로 좌우가 동일한 분포를 따른다.
- 표본의 크기가 적을때는 표준정규분포를 위에서 눌러 놓은 것과 같은 형태를 보이지만 표본이 커져서(30개 이상) 자유도가 증가하면 표준정규분포와 거의 같은 분포가 된다.
- 데이터가 연속형일 경우 활용한다.
- **두 집단의 평균이 동일**한지 알고자 할 때 검정통계량으로 활용된다.
- 표준정규분포와 같이 평균 값이 0이며, 자유도에 따라 분포의 모양이 변화한다.
- 자유도가 30미만인 경우, 표준정규분포에 비해 양쪽 끝이 평평하고 두터운 꼬리 모양을 가진다.



###### 5) X<sup>2</sup>-분포 (X<sup>2</sup>-distribution) (카이제곱분포)

- 모평균과 모분산이 알려지지 않은 모집단의 모분산에 대한 가설 검정에 사용되는 분포이다.
- **두 집단 간의 동질성 검정에 활용**된다.
- 확률변수 X가 표준정규분포(Z)를 따를 때, 자유도가 k인 카이제곱분포를 따른다. 자유도는 표본 자료 중 모집단에 대한 정보를 주는 독립적인 표본 자료의 수와 같으며, 분할표에서의 행과 열의 개수를 통해 구할 수 있다. (자유도(df) = (r-1)(c-1), r=행의 개수, c=열의 개수)



###### 6) F-분포 (F-distribution)

- **두 집단간 분산의 동일성 검정**에 사용되는 검정 통계량의 분포이다.
- 확률변수는 항상 양의 값만을 갖고 카이제곱분포와 달리 자유도를 2개 가지고 있으며 자유도가 커질수록 정규분포에 가까워진다.



#### 2. t-검정 (t-test) (p.72)

##### 가. 일표본 t-검정 (one sample t-test)

###### 1) 일표본 t-검정이란?

- **단일모집단에서 관심이 있는 연속형 변수의 평균(&mu;)값을 특정 기준값과 비교**하고자 할 때 사용하는 검정방법이다.

###### 2) 일표본 t-검정의 가정

- 일표본 t-검정에서는 **모집단의 구성요소들이 정규분포를 이룬다는 가정** 하에 검정통계량의 값을 계산한다.
- **종속형 변수는 연속형** 변수여야 하며, **검증하고자 하는 기준값이 있어야** 한다.

###### 3) 일표본 t-검정의 단계

- 1단계 : 가설 설정

- 2단계 : 유의수준 설정

- 3단계 : 검정통계량의 값 및 유의확률 계산

- 4단계 : 기각여부 판단 및 의사결정

    ​    

###### 4) R을 활용한 일표본 t-검정

##### 나. 대응표본 t-검정 (paired sample t-test)

###### 1) 대응표본 t-검정이란?

- **단일모집단에 대해 두 번의 처리를 가했을 때, 두 개의 처리에 따른 평균의 차이를 비교**하고자 할 때 사용하는 검정방법.

###### 2) 대응표본 t-검정의 가정

- **대응표본 t-검정에서는 모집단의 관측값이 정규성(정규분포를 만족한다는 가정)을 만족**해야 한다.

###### 3) 대응표본 t-검정의 단계

- 1단계 : 가설 설정
- 2단계 : 유의수준 설정
- 3단계 : 검정통계량의 값 및 유의확률 계산
- 4단계 : 기각여부 판단 및 의사결정

###### 4) R을 활용한 대응표본 t-검정

##### 다. 독립표본 t-검정 (independent sample t-test)

###### 1) 독립표본 t-검정이란?

- **두 개의 독립된 모집단의 평균을 비교 할때 사용하는 검정방법**

###### 2) 독립표본 t-검정의 가정

- 두 모집단은 **정규성**을 만족해야 함.
- 두 모집단은 서로 **독립적**이어야 함
- **등분산성** 가정을 만족해야 함
- 독립변수는 범주형, 종속변수는 연속형이어야 함

> 등분산성 : 두 모집단의 분산이 서로 같음을 의미

###### 3) 독립표본 t-검정의 단계

- 1단계 : 가설설정
- 2단계 : 유의수준 설정
- 3단계 : 등분산 검정
- 4단계 : 검정통계량의 값 및 유의확률 계산

###### 4) R을 활용한 독립표본 t-검정



#### 3. 분산분석 (ANOVA) (p.80)

##### 가. 분삭분석의 개념

-   두 개 이상 집단들의 평균 간 차이에 대한 통계적 유의성을 검증하는 방법

##### 나. 일원배치 분석 (One-way ANOVA)

###### 1) 특징

-   하나의 범주형 변수의 영향을 알아보기 위해 사용되는 검증 방법
-   모집단의 수에 제한이 없음
-   F 검정 통계량을 이용한다

###### 2) 가정

-   각 집단의 측정치는 서로 독립적이며, 정규분포를 따른다. (정규성 가정)
-   각 집단 측정치의 분산은 같다. (등분산 가정)

###### 3) 통계적 모형

###### 4) 분산분석표

###### 5) 가설검정

-   귀무가설(H<sub>0</sub>) : 집단 간 모평균에는 차이가 없다.
-   대립가설(H<sub>1</sub>) : 집단 간 모평균이 모두 같다고 할 수 없다.

###### 6) 사후 검정

-   귀무가설이 기각되었을 때, 어떤 집단들에 대해서 평균의 차이가 존재하는지를 알아보기 위해 실시하는 분석
-   종류 : 던칸(Duncan)의 MRT(Multiple Range Test) 방법, 피셔(Fisher)의 최소유의차(LSD; Least S... Difference)방법, 튜키(Tukey)의 HSD방법, Scheffe의 방법 등이 있다.

###### 7) R을 이용한 일원배치 분산 분석

##### 다.  이원배치 분산분석 (Two-way ANOVA)

###### 1) 특징

-   두 개의 범주형 변수 A, B의 영향을 알아보기 위해 사용되는 검증 방법

###### 2) 가정

-   정규성, 등분산성

###### 3) 통계적 모형

###### 4) 분산분석표

###### 5) 가설검정

-   귀무가설(H<sub>0</sub>) : 변수에 따른 종속변수의 값(반응값)에는 차이가 없다. &alpha; 와 &beta; 변수의 상호작용 효과가 없다.
-   대립가설 (H<sub>1</sub>) : 변수에 따른 종속변수의 값(반응값)에는 차이가 있다.&alpha; 와 &beta; 변수의 상호작용 효과가 있다.

###### 6) 교호작용 (Interaction Effection)

-   두 가지 이사의 특정 변수 조합에서 일어나는 효과

##### 라. 실험계획법 (DOE, Design Of Experiment)

###### 1) 실험 계획법의 개념

-   시스템이나 프로세스의 결과에 영향을 미치는 인자를 도출하고, 측정 데이터를 통계적으로 분석하기 위한 실험을 설계하는 방법을 의미한다.

###### 2) 계획 설계의 목적

###### 3) 실험계획의 원리

-   랜덤화의 원리 (Randomization) :
-   반복의 원리 (Replication) :
-   블록화의 원리(Blocking) : 
-   직교화의 원리 (Orthogonality) :
-   교락의 원리 (Confounding) : 

###### 4) 주요 용어

-   인자 (Factor) :
-   특성치 (Characteristic Value) :
-   수준 (Level) :
-   주효과 (Main Effect) :
-   교호효과 (Interaction Effect) :
-   교락 (Confounding) :
-   블록 (Block) :
-   반복 (Replication) :
-   중복 (Repetition) :

###### 5) 실험계획법의 종류

1.   요인배치법 (Factorial Design)
2.   분할법 (Split-plot Design)
3.   교락법 (Confounding method)
4.   난괴법 (Randomized Block Design)

#### 4. 교차분석 (p.87)

##### 가. 교차분석 (검정)

###### 1) 교차분석의 개념 및 특징

-   범주형 자료인 두 변수 간의 관계를 알아보기 위해 실시하는 분석 기법
-   적합도 검정, 독립성 검정, 동질성 검정에 사용
-   카이제곱($x^2$) 검정 통계량을 이용

###### 2) 교차표

##### 나. 적합도 검정

###### 1) 적합도 검정의 의미

-   모집단 분포에 대한 가정이 옳게 되었는지를 관측 자료와 비교하여 검정하는 것

###### 2) 가설 설정

###### 3) 검정 통계량

###### 4) 자유도

-   $df = k - 1$

###### 5) R을 이용한 적합도 검정

-   chisq.test(x, y, p)

##### 다. 독립성 검정

###### 1) 독립성 검정의 의미

-   범주화 된 두 변수 A, B 사이의 관계가 독립인지 아닌지를 검정
-   검정 통계량을 계산할 때는 교차표를 활용

###### 2) 가설 설정

-   두 변수 A, B가 서로 독립적으로 관측값에 영향을 미치는 지의 여부를 검정
-   귀무가설 : 두 변수 사이에 연관이 없다. (독립이다)
-   대립가설 : 두 변수 사이에 연관이 있다. (종속이다)

###### 3) 검정 통계량

###### 4) 자유도

-   R : 행의 수, C: 열의 수
-   $df = (R-1)(C-1)$

##### 라. 동질성 검정

###### 1) 동질성 검정의 의미

-   교차표를 활용하며, 계산법과 검증법은 모두 독립성 검정과 같은 방법으로 진행

###### 2) 가설 설정

-   j = 1, 2, ..., c 이다.
-   귀무가설 : P<sub>1j</sub> = P<sub>2j</sub> = ... = P<sub>rj</sub> (모든 P<sub>nj</sub> (n=1,2,...r)는 동일하다)
-   대립가설 : Not H<sub>0</sub> (P<sub>nj</sub> (n=1,2,...r) 중 다른 값이 하나 이상 존재한다.)

###### 3) 검정 통계량

###### 4) 자유도

-   $df = (R-1)(C-1)$   R: 행의 수, C: 열의 수

#### 5. 중심극한정리 (Central Limit Theorem)

##### 가. 개념

-   표본의 개수 n이 커질수록 표본 평균의 분포(표집분포)가 정규분포에 가까워지는 현상을 의미
-   평균이 &mu;이고, 분산이 &sigma;<sup>2</sup> 인 모집단에서 크기가 n인 확률표본을 추출.

##### 나. 중심극한정리

-   $N(\mu, \dfrac{\sigma^2}{n})$
-   $Z = \dfrac {\overline {X} - \mu}{\dfrac {\sigma}{\sqrt{n}}}$

### 2절 회귀분석 

#### 1. 정규화 선형회귀 (Regularized Linear Regression) (p.92)

-   선형회귀 계수에 대한 제약 조건을 추가하여 모델이 과도하게 최적화되는 현산(과적합, Overfitting)을 막는 방법
-   계수의 크기를 제한하는 방법으로 제약조건을 추가한다.
-   제약 조건의 종류에 따라 Ridge회귀, LASSO회귀, Elastic Net 회귀모형

##### 가. 릿지회귀 (Ridge Regression)

-   가중치들의 제곱합(Squared Sum of weight)을 최소화하는 것을 제약조건으로 추가하는 기법
-   가중치의 모든 원소가 0에 가까워지는 것을 원하며, 규제 방식을 L2 규제(Penalty)라고 한다.
-   &lambda;는 제약조건의 비중을 조절하기 위한 하이퍼 모수(Hyper parameter)에 해당하며, 람다가 커지면 가중치의 값들이 작아지며, 정규화 정도가 커진다. 람다가 작아지면 정규화 정도가 작아지고, 람다가 0이 되면 일반적인 선형회귀 모형이 된다.

##### 나. 라쏘회귀 (LASSO Regression)

-   라쏘 (Least Absolute Shrinkage and Selection Operator)는 가중치 절대값의 합을 최소화하는 것을 제약조건으로 추가하는 기법
-   가중치가 0에 가까워질 뿐, 실제 0이 되지는 않는다. 하지만 중요하지 않은 가중치는 0이 될 수도 있다.
-   라쏘에서 사용하는 규제방식을 L1 규제라고 한다.

##### 다. 엘라스틱넷(Elastic Net)

-   릿지와 라쏘를 결합한 모델
-   &lambda;<sub>1</sub> 와 &lambda;<sub>2</sub> 두 개의 하이퍼 모수를 가짐

#### 2. 일반화 선형회귀 (GLM, Generalized Linear Regression) (p.93)

-   종속변수를 적절한 함수로 변화시켜 f(x)를 정의한 후, 이 f(x)와 독립변수를 선형 결합으로 모형화하는 '일반화 선형모형(glm)'을 이용한다.
-   일반화 선형모형은 3가지 성분에 의해서 정의 된다.
    -   랜덤성분 (Random Component)
    -   체계적 성분 (systematic component)
    -   연결함수 (link function)

#### 3. 회귀분석의 영향력 진단 (p.94)

-   영향력 진단이란 적합된 회귀모형의 안전성을 평가하는 통계적인 방법이다.
-   회귀직선의 기울기에 영향을 크게 주는 점을 ==영향점==이라고 한다.

#### 4. 더빈 왓슨(Durbin Watson) 검정

-   오차항이 독립성을 만족하는지를 검정하기 위해 사용
-   더빈 왓슨 동계량이 2에 가까울수록 오차항의 자기상관이 없음을 의미

#### 5. 벌점화된 선택기준 : 변수 선택의 기준으로 사용되는 통계량

##### 가. 수정된 결정계수 (Adjuestd R square)

##### 나. Mallow's CP

#### 6. 변수 변환 (p.96)

-   회귀분석의 기본가정인 ==정규성, 선형성, 등분산성== 가정을 만족하지 못하는 경우, 변수를 변환함으로써 교정할 수 있다.

##### 가. 변수변환법의 종류

-   로그변환, 제곱근변환 : 대부분의 값이 작은 값으로 구성되어 있는 데이터를 정규화하기 위해 사용
-   지수변환, 제곱변환 : 대부분의 값이 큰 값으로 구성되어 있는 데이터를 정규화하기 위해 사용

##### 나. 더미변수 생성

-   더미변수는 변수의 범주의 수 -1 개 이다.

##### 다. Box-cox 변환

-   정규분포를 따르지 않는 반응변수를 정규성을 만족하도록 변환하기 위해 사용하는 방법
-   &lambda;는 우도함수를 최대화 시키는 조건으로 계산된다.

### 2장 정형 데이터마이닝

### 1절 데이터마이닝 개요

#### 1. Feature Selection (변수선택) (p.108)

##### 가. Filter Method

- 각 변수들에 대해 통계적인 점수를 부여 후, 부여된 점수를 이용하여 변수의 순위를 매기고 변수 선택을 진행
- 예) Chi squared test, information gain, correlation coefficient scores 등

##### 나. Wrapper Method

- 변수간의 상호 작용을 감지할 수 있도록 **변수의 일부만을 모델링에 사용한 후 그 결과를 평가하는 작업을 반복**하면서 변수를 선택해 나가는 방법
- 예) recursive feature elimination algorithm

##### 다.  Embedded Method

- Filter method 와 wrapper method를 결합하여 어떤 변수가 가장 크게 기여하는지를 찾아내는 방법으로 **과적합을 줄이기 위해 내부적으로 규제를 가하는 방식**이 사용된다.
- 예) LASSO, Ridge Regression, Elastic Net 등

#### 2. DeepLearning

##### 가. 머신러닝

- 인공지능에 포함되는 개념으로, 경험적인 데이터를 바탕으로 기계가 지식을 습득하여 스스로 성능을 향상하는 기술을 의미
- 학습 방법에 따라 구분
    - 지도학습 (Supervised learning) : 출력값에 대한 정답을 컴퓨터에게 알려줌
    - 비지도학습 (Unsupervised learning) : 출력값에 대한 정답을 컴퓨터에게 안 알려줌
    - 강화학습 (Reinforcement learning) : 출력값의 정답이 주어지지 않은 상태에서 일련의 행동 결과에 대한 보상(reward)이 주어짐

##### 나. 딥러닝

- **인공신경망에 기반을 둔 기계학습**의 한 종류로, 여러 비선형 변환기법의 조합을 통해 많은 데이터로 부터 특징들을 학습하는 방법
- 종류
    - DNN (Deep Neural Network, 심층 신경망) : 입력층과 출력층 사이에 여러개의 은닉층들로 이루어진 신경망 구조
    - 예) 암 진단 시스템, 주가지수 예측, 기업신용평가, 환율 예측 등
    - CNN (Convolutional Neural Network, 합성곱 신경망) : 다계층 퍼셉트론의 한 종류로 여러개의 합성곱 계층과 일반적인 인공 신경망 계층들로 이루어져 있음.
    - 예) 자율 주행 자동차, 이미지, 텍스트, 사운드, 비디오 인식 및 식별 등의 영상, 그림 인식 분야 등
    - RNN (Recurrent Neural Network, 순환 신경망) : 시간의 흐름에 따라 변화하는 데이터를 학습하기 위한 딥러닝 알고리즘으로 기준 시점과 다음 시점에 네트워크를 연결하여 구성한 인공신경망이라고 할 수 있다.
    - 예) 음성 인식, 자동 번역, 단어 의미 판단, 이미지 캡션 생성 등의 자연어 처리 분야 등

##### 다. 프로그래밍 언어별 딥러닝 지원 라이브러리

1) 파이썬
2) C++
3) JAVA
4) R



### 2절 분류분석

#### 1. 나이브 베이즈 분류 (Naive Bayes Classification) (p. 112)

##### 가. Bayes theorem (베이즈 정리)

- **두 확률 변수의 사전 확률과 사후 확률 사이의 관계를 나타내는 정리**

- 사건 B가 일어난 것을 전제로 한 사건 A의 조건부 확률을 다음과 같이 구할 수 있는것

- >  $P(A|B) = \dfrac{P(B\cap A)}{P(B)} = \dfrac {P(A)P(B|A)} {P(B)} = \dfrac {P(A)P(B|A)} {P(A)P(B|A) + P(A^C)P(B|A^C)}$

- P(A|B) : 사건 B가 발생했을 때 사건 A가 발생할 확률 > 사후확률 (posterior)

- P(B|A) : 사건 A가 발생했을 때 사건 B가 발생할 확률 > 우도 (likelihood)

- $P(A \cap B)$ : 사건 A와 B가 동시에 발생할 확률

- P(A) : 사건 A가 발생할 확률 > 사전확률 (prior)

- P(B) : 사건 B가 발생할 확률 > 관찰값 (evidence)

- 위 식을 다음과 같은 식으로도 표현 가능

- > $posterior = \dfrac {prior * likelihood} {evidence}$

![naive-bayes](https://user-images.githubusercontent.com/291782/149884588-2373a115-d8ea-400f-b5e7-66a7ae7cf3c5.png)

##### 나. 나이브 베이즈 분류의 개념

- 변수들에 대한 조건부 독립을 가정하는 알고리즘으로, 어떤 데이터가 특정 클래스에 속하는지를 분류하는 알고리즘이다.
- 문서를 여러 범주(예, 스팸, 경제, 스포츠) 중 하나로 판단하는 문제에 대한 솔루션으로 사용 가능

##### 다. 나이브 베이즈 분류의 계산

- 속성값에 대해 다른 속성이 독립적이라는 가정은 **클래스 조건 독립성 (Class conditional independence)**라 한다.

#### 2. K-Kearest Neighbor Classification (KNN, K-최근접 이웃 알고리즘) (p.114)

- 특정 범주로 나뉘어진 데이터가 있을 때, 새로운 데이터가 추가 된다면 어떤 범주로 분류할 것인지를 결정할 때 사용할 수 있는 분류 알고리즘. 지도학습의 한 종류

##### 가. KNN 알고리즘의 원리

- 새로운 데이터의 클래스를 해당 데이터와 가장 가까운 k개 데이터들의 클래스(범주)로 결정한다.
- 이웃간의 거리를 계산할 때 **유클리디안 거리**(대표적 사용), 맨하탄 거리, 민코우스키 거리 등을 사용

##### 나. k의 선택

- k의 선택은 학습의 난이도와 데이터의 개수에 따라 결정될 수 있으며, 일반적으로는 훈련 데이터 개수의 제곱근으로 설정.

##### 다. KNN 분류 예시

##### 라. KNN의 장단점

- 장점
    - 사용이 간단
    - 범주를 나눈 기준을 알지 못해도 데이터를 분류할 수 있다.
    - 추가된 데이터의 처리가 용이하다
- 단점
    - k값의 결정이 어렵다.
    - 비수치 데이터의 경우 유사도를 정의하기 어렵다.
    - 데이터 내에 이상치가 존재하면 성능에 큰 영향을 받는다.

#### 3. SVM (Support Vector Machine) (p.116)

##### 가. 개념

- 기계학습 분야 중 하나로 패턴인식, 자료 분석 등을 위한 지도학습 모델이며 주로 회귀와 분류 문제 해결에 사용된다.
- 주어진 데이터 집합을 바탕으로 하여 새로운 데이터가 어떤 범주에 속할 것인지를 판단하는 **비확률적 이진 선형 분류 모델을 생성**한다.

##### 나. 작동 원리

- 데이터가 사상된 공간에서 경계로 표현되며, 공간상에 존재하는 여러 경계 중 가장 큰 폭을 가진 경계를 찾는다.
- 각 그룹을 구분하는 분류자를 결정 초평면(decision hyperline)
- 초평면에 가장 가까이에 붙어있는 최전방 데이터들을 서포트 벡터(support vector)
- 서포트 벡터와 초평면 사이의 **수직거리를 마진**(margin)이라 한다.

![svm-desc](https://user-images.githubusercontent.com/291782/149886433-8723750d-fda3-4528-bba4-4a5a1858b112.png)

> 초평면은 어떤 n차원의 공간보다 한 차원이 낮은 n-1차원의 하위공간(sub space)를 의미함. 즉 2차원 공간에서 초평면은 선이 된다.

##### 다. SVM의 장단점

- 장점
    - 분류와 예측에 모두 사용 가능
    - 신경망 기법에 비해 과적합 정도가 낮다.
    - 예측의 정확도가 높다.
    - 저차원과 고차원의 데이터에 대해서 모두 잘 작동한다.
- 단점
    - 데이터 전처리와 매개변수 설정에 따라 정확도가 달라질 수 있다.
    - 예측이 어떻게 이루어지는지에 대한 이해와 모델에 대한 해석이 어렵다.
    - 대용량 데이터에 대한 모형 구축 시 속도가 느리며, 메모리 할당량이 크다.



### 3절 군집분석

#### 1. Resampling (재표본추출) (p.118)

- 표본을 수많이 재추출하고, 재추출된 표본에 모형을 적합하게 함으로써 생성된 분류기의 성능 측정에 대한 통계적 신뢰도를 높이는 방식이 리샘플링 기법이다. 대표적으로 k-fold cross validation, 홀드아웃 방법, 붓스트랩 등이 있다.

##### 가. K-Fold cross validation

- 데이터를 k개의 집단으로 나눈 뒤 k-1개의 집단으로 분류기를 학습 시키고, 나머지 1개의 집단으로 분류기의 성능을 테스트
- 위 과정을 k번 반복하여 모든 데이터가 학습과 검증에 사용될 수 있도록 하고, 최종적으로 k번의 테스트를 통해 얻은 MSE (평균제곱오차)값들의 평균을 해당 모델의 MSE 값으로 사용

##### 나. 붓스트랩 (bootstrap)

- 모집단에서 추출한 표본(샘플)에 대해서 또 다시 재표본(샘플)을 여러 번 추출하여 모델을 평가하거나 데이터의 분포를 파악하는 재표본추출 방법
- **단순랜덤 복원추출법**을 사용하여 표본을 여러개 생성하므로, 특정 데이터가 샘플에 포함될수도 있고, 안될수도 있다.
- 샘플에 한 번도 선택되지 않는 데이터가 발생할 확률은 36.8%이며, 이러한 데이터를 OOB (out-of-bag) 데이터라고 하며, OOB데이터의 실제값과 예측값 사이의 오차로 정의되는 값을 OOB error라고 한다.

#### 2. 군집화 기법 종류 (p.120)

##### 가. 밀도기반 군집분석

##### 나. 격자기반 군집분석



#### 3. 군집분석의 타당성 지표 (p.121)

##### 가. Silhouette (실루엣)

- 군집내의 응집도와 군집 간 분리도를 이용한 지표로, 군집 내 요소간의 거리가 짧고 서로 다른 군집간 거리가 멀수록 커진다.
- 완벽한 군집화가 이루어졌을 경우 1, 군집화가 전혀 이루어지지 않은 경우에는 -1 값을 가진다.

##### 나. Dunn Index

- 군집 간 거리의 최소값을 분자, 군집 내 요소 간 거리의 최대값을 분모로 하는 지표
- 군집 간 거리는 멀고, 군집 내 분산은 작을수록 군집화가 잘 이루어진 것이기 때문에 Dunn Index가 클수록 군집화가 잘 형성되어 있다고 볼 수 있음.

#### 4. BMU (Best-Matching Unit) (p.121)

- SOM (Self Organizing Maps) 에서 **표본 벡터와 거리가 가장 가까운 프로토타입 벡터**를 선택하는데, BMU는 이 때 선택된 프로토타입 벡터를 나타내는 용어이다.



### 3장 비정형 데이터마이닝

### 1절 텍스트마이닝

#### 1. 텍스트 마이닝 (Text Mining) (p.129)

-   입력된 텍스트를 구조화해 그 데이터에서 패턴을 도출한 후 결과를 평가 및 해석하는 일련의 과정
-   다양한 포맷의 문서로부터 텍스트를 추출해 단어 구성에 따라 데이터 마트를 구성한다.
-   인터넷 데이터, 소셜미디어 데이터 등과 같은 자연어로 구성된 비정형 텍스트 데이터 속에서 정보나 관계를 발견하는 분석 기법

#### 2. 텍스트 마이닝 기능

-   문서요약 (Summarization)
-   문서 분류 (classification)
-   문서 군집 (clustering)
-   특성 추출 (feature extraction)

#### 3. 정보 검색의 적절성

-   분석 결과를 평가하기 위해 **정확도와 재현율**을 사용한다.
-   정확도 (precision): 분석 모델이 정답이라고 예측한 결과중에서 실제로 정답인 경우의 비율 (TP / (TP + FP))
-   재현율 (Recall) : 실제로 정답인 것들 중에서 분석 모델이 정답이라고 내놓은 결과의 비율 (TP / (TP + FN))

![precision_recall](https://user-images.githubusercontent.com/291782/150641056-4425fc9d-36be-4369-9c35-f76b1522c204.png)

#### 4. Corpus

-   데이터마이닝의 절차 중 데이터의 정체, 통합, 선택, 변환의 과정을 거친 구조화된 단계로 더 이상 추가적인 절차 없이 데이터 마이닝 알고리즘 실험에 활용될 수 있는 상태이다.

#### 5. Term-Document Matrix

-   텍스트 마이닝을 불러온 문서에 대해 plain text로 전환, 공백 제거, lowercase로 변환, 불용어(stopward) 처리, 어간추출(stemming) 등의 작업을 수행한 다음에 문서 번호와 단어 간의 사용 여부 또는 빈도수를 이용해 matrix를 만드는 작업이 term document matrix이다.

#### 6. Dictionary

-   텍스트 마이닝 분석 시 사용하고자 하는 단어들의 집합

#### 7. 감성분석

-   문장에서 사용된 단어의 긍정과 부정 여부에 따라 전체 문장의 긍정/부정 여부를 평가한다.
-   브랜드에 대한 평판 분석 가능

#### 8. 한글 처리

-   R의 텍스트 마이닝 패키지 : KoNLP
-   명사를 추출할때는 extractNoun("문장") 함수를 사용

#### 9. 워드 클라우드

-   문서에 포함된 단어들의 사용 빈도를 효과적으로 보여주기 위해 단어들을 크기, 색 등으로 나타내어 구름 등과 같은 형태로 시각화 하는 기법





### 2절 사회연결망 분석

#### 1. 사회연결망 분석 (p.135)

##### 가. SNA (Social Network Analysis) 정의

-   개인과 집단들 간의 관계를 노드와 링크로 모델링하여 그것의 위상구조와 확산 및 진화 과정을 계량적으로 분석하는 방법론
-   개인의 인간관계가 인터넷으로 확대된 사람 사이의 네트워크
-   개인 또는 집단이 하나의 노드(node), 연결은 선(link 또는 edge)으로 표현됨

##### 나. SNA 분류

1.   집합론적 방법
     -   각 객체들 간의 관계를 관계 쌍(pairs of elements)으로 표현
2.   그래프 이론을 이용한 방법
     - 객체를 점(노드 or 꼭지점)으로 표현하고, 연결은 두 점을 연결하는 선으로 표현
3.   행렬을 이용한 방법
     - 각 객체를 행과 열에 배치하고, 각 객체간의 관계가 존재하면 1을 넣고, 존재하지 않으면 0을 넣음.

#### 2. 사회연결망 분석에서 네트워크 구조를 파악하기 위한 기법

##### 가. 중심성(Centrality)

- 연결정도 중심성 (Degree centrality) : 한 점에 직접적으로 연결된 점들의 합
- 근접 중심성 (Closeness centrality) : 한 노드로부터 다른 노드에 도달하기까지 필요한 최소 단계의 합
- 매개 중심성 (Betweenness centrality) : 네트워크 내에서 한 점이 담당하는 매개자 혹은 중재자 역할의 정도
- 위세 중심성 (Eigenvector centrality) : 보나시치(Bonacich) 권련지수 : 위에 중심성의 일반적인 형태로, 연결된 노드의 중요성에 가중치를 둬 노드의 중심성을 측정하는 방법

#### 3. SNA 적용

- 소셜 네트워크 분석은 통신, 온라인 소셜 미디어, 게임 및 유통업체에서 관심이 높다.
- 분석용 솔루션으로는 KXEN, SAS, XTRACT, Indiro, Onalytica, Unicet, Pajek, Inflow 등이 있다.

#### 4. SNA 단계

1. 그래프 생성단계
2. 그래프를 목적에 따라 가공하여 분석하는 단계
3. 커뮤니티를 탐지하고 각 객체 또는 노드의 역할(롤)을 정의해 어떠한 롤도 다른 객체들에게 영향력을 더 효율적으로 줄 수 있는지를 정의하는 단계
4. 위 결과를 데이터화하여 다른 데이터마이닝 기법과 연계하는 단계



#### 5. R에서의 SNA

##### 가. 네트워크 레벨 통계량

degree, shortest paths, reachability, density, reciprocity, transitivity, triad census 등

##### 나. 커뮤니티의 수를 측정하는 방법 (community detection)

1. WALKRAP 알고리즘
    - 일련의 random walk 과정을 통해 커뮤니티를 발견한다.
2. Edge Betweenness method
    - 그래프에 존재하는 최단거리 (shortest path) 중 몇 개가 그 edge (연결, link)를 거쳐가는 지를 이용해 edge-betweenness 점수를 측정한다.

#### 6. 활용방안

- 소셜 네트워크 분석은 데이터가 몇개의 집단으로 구성되는지, 집단 간의 특징은 무엇이고, 해당 집단에서 영향력 있는 고객은 누구인지, 시간의 흐름과 고객 상태의 변화에 따라 다음에 누가 영향을 받을지를 기반으로 churn/acquisition prediction, fraud, product recommendation 등에 활용한다.





### 4장 서술형 문제



## ADP 데이터 분석 END



## ADsP 데이터 분석 START
### 4장 통계 분석

### 1절 통계분석의 이해

#### 2. 통계자료의 획득 방법 (p.282)

##### 가. 총 조사 / 전수 조사 (census)

-   많은 비용과 시간이 소요되므로 특별한 경우를 제외하고는 사용되지 않음. (eg. 인구주택 총 조사)

##### 나. 표본조사 

-   모집단에서 샘플을 추출하여 진행하는 조사
-   모집단 (population) : 대상 집단 전체
-   원소 (element) : 모집단을 구성하는 개체
-   표본 (sample) : 조사하기 위해 추출한 모집단의 일부 원소
-   모수 (parameter) : 표본 관측에 의해 구하고자 하는 모집단에 대한 정보
-   모집단의 정의, 표본의 크기, 조사 방법, 조사기간, 표본추출방법을 정확히 명시해야 함



##### 다. 표본 추출 방법 4가지 (중요)

1.   단순랜덤 추출법 (simple random sampling)

     -   각 샘플에 번호를 부여하여 n개를 추출하는 방법으로 각 샘플은 선택될 확률이 동일하다. (복원, 비복원 추출)

2.   계통추출법 (systematic sampling)

     -   단순랜덤 추출법의 변형된 방식으로 샘플을 나열하여 K개씩 n개의 구간으로 나누고 첫 구간에서 하나를 임의로 선택한 후에 K개식 띄어서 n 개의 표본을 선택
     -   ![systematic-sampling](https://user-images.githubusercontent.com/291782/161560760-0d60d365-a300-4262-8b09-5e9d64125e21.png)

3.   집락추출법 (cluster random sampling)

     -   군집을 구분하고 군집별로 단순랜덤 추출법을 수행한 후, 모든 자료를 활용하거나 샘플링하는 방법
     -   ![cluster-random-sampling](https://user-images.githubusercontent.com/291782/161560900-294b7296-b204-41f2-9170-0f60ae4d9fc4.png)

4.   층화추출법 (stratified random sampling)

     -   이질적인 원소들로 구성된 모집단에서 각 계층을 고루 대표할 수 있도록 표본을 추출하는 방법으로, 유사한 원소끼리 몇 개의 층(stratum)으로 나누어서 각 층에서 랜덤 추출하는 방법
     -   ![stratified-random-sampling](https://user-images.githubusercontent.com/291782/161561325-a774c94f-ce60-4430-a2fb-f91dcdf969c2.png)

     

     

     ##### 라. 측정 (measurement)

     측정방법 (아주 중요)

     -   질적처도 : 범주형 자료, 숫자들의 크기 차이가 계산되지 않는 척도
         -   명목척도 : 측정 대상이 어느 **집단**에 속하는지 분류할 때 사용 (성별, 출생지 구분)
         -   순서척도 : 측정 대상의 **서열관계**를 관측하는 척도 (만족도, 선호도, 학년, 신용등급)
     -   양적척도 : 수치형자료, 숫자들의 크기 차이를 계산할 수 있는 척도
         -   구간척도(등간척도) : 측정 대상이 갖고 있는 **속성의 양**을 측정하는 것으로 구간이나 구간 사이의 **간격이 의미가 있는** 자료 (온도, 지수)
         -   비율척도 : 간격(차이)에 대한 비율이 의미를 가지는 자료, **절대적인 기준인 0이 존재**하고 **사칙연산이 가능**하며 제일 많은 정보를 가지는 척도 (무게, 나이, 시간, 거리)

     순서척도는 명목척도와 달리 매겨진 숫자의 크기를 의미있게 활용 가능 (예: 1등이 2등보다 성적이 높다)

     구간척도는 절대적 크기는 측정할 수 없기 때문에 사칙연산 중 더하기와 빼기는 가능. 곱하기나 나눗셈은 불가능

     

     

     #### 3. 통계분석 (p.285)

     

     #### 4. 확률 및 확률분포 (p.285)

     ##### 나. 확률분포

     1.   이산형 확률변수

          -   베르누이 확률분포 (Bernoulli distribution)

              -   결과가 2개만 나오는 경우 **성공 또는 실패** (예. 동전 던기지, 시험의 합격/불합격 등)
              -   $P(X = x) = P^x . (1-p)$<sup>1-x</sup> 
              -   (x= 1 or 0), 기댓값: $E(x) = p$, 분산 :$var(x) = p(1-p)$
              -   예) 추신수가 안타를 칠 확률은 베르누이 분포를 따른다.
          -   이항분포 (Binomial distribution)

              -   베르누이 시행을 n번 반복했을 때 k번 성공할 확률
              -   n번 시행 중에 각 시행의 확률이 p일 때, k번 성공할 확률분포
              -   $P(X = k) = _nC_kP^k(1-p)$<sup>n-k</sup> , $_nC_k = \dfrac {n!}{k!(n-k)!}$
              -   기댓값 : $E(X) = np$, 분산 : $V(X) = np(1-p) $  (단, n과 k가 1이면 베르누이 시행)
              -   추신수가 오늘 경기에서 5번 타석에 들어와서 3번 안타를 칠 확률은 이항분포를 따른다. (n=5, k=3, 안타를 칠 확률 P(x) = 타율로 적용 가능)
              -   성공할 확률 p가 0이나 1에 가깝지 않고 n이 충분히 크면 이항분포는 정규분포에 가까워 진다. 성공할 확률 p가 1/2에 가까우면 종모양이 된다.
          -   기하분포 (Geometric distribution)
              -   성공확률이 p인 베르누이 시행에서 첫번째 성공이 있기까지 X번 실패할 확률
              -   예) 추신수가 오늘 경기에서 5번 타석에 들어와서 3번째 타석에서 안타를 칠 확률은 기하분포를 따른다.
          -   다항분포 (Multinomial distribution)
              -   이항분포를 확장한 것으로 세가지 이상의 결과를 가지는 반복 시행에서 발생하는 확률 분포
          -   포아송분포 (Poisson distiribution)
              -   시간과 공간 내에서 발생하는 사건의 발생횟수에 대한 확률분포
              -   예) 책에 오타가 5page 당 10개씩 나온다고 할 떄, 한 페이지에 오타가 3개 나올 확률, 추신수가 최근 5경기에서 홈런을 쳤을 경우, 오늘 경기에서 홈런을 못 칠 확률은 포아송 분포
              -   &lambda; (람다) = 정해진 시간 안에 어떤 사건이 일어날 횟수에 대한 기댓값, y= 사건이 일어난 수
              -   $P = \dfrac {\lambda^ne^{-\lambda}} {n!}$ (e는 자연상수)
              -   기댓값 : $E(X) = \lambda$, 분산 : $V(X) = \lambda $

     2.   연속형 확률변수

          - 가능한 값이 실수의 어느 특정구간 전체에 해당하는 확률변수 (확률밀도함수)

          - $ f(x)\ge 0 $     $\int_{-\infty}^{\infty}f(x)dx = 1$

          - 균일분포 (일양분포, Uniform distiribution)

              - 모든 확률변수 X가 균일한 확률을 가지는 확률분포 (다트의 확률분포)
              - $E(X) = \dfrac {a+b}{2}, Var(X) = {(b-a)^2}{12}$
              - ![uniform-distribution](https://user-images.githubusercontent.com/291782/161756609-ae577e06-5c55-410f-b205-63f1c5afd9b6.png)

          - 정규분포 (Normal distribution)

              - 평균이 &mu; (뮤) 이고, 표준편차가 &sigma; (시그마) 인 X의 확률밀도 함수
              - 표준편차가 클 경우 퍼져보이는 그래프가 나타남
              - 표준정규분포는 평균이 0 이고, 표준편차가 1인 정규분포
              - 정규분포를 표준정규분포로 만들기 위해서는 $Z = \dfrac {X - \mu} {\sigma}$  식을 이용
              - ![normal-distribution](https://user-images.githubusercontent.com/291782/161757336-f8a45f83-945c-4560-98b3-eee70cde4fa1.png)

          - 지수분포 (Exponential distribution)

              - 어떤 사건이 발생할 때까지 경과 시간에 대한 연속확률분포이다.
              - 예) 전자렌지의 수명시간, 콜센터에 전화가 걸려올때 까지의 시간, 은행에 고객이 내방하는데 걸리는 시간, 정류소에서 버스가 올 때까지의 시간
              - ![exponential-distribution](https://user-images.githubusercontent.com/291782/161757625-0f01dde3-c578-4d62-b92d-8e2c667ec95c.png)

          - t분포 (t-distribution)

              - 표준정규분포와 같이 평균이 0을 중심으로 좌우가 동일한 분포를 따른다.
              - 표본이 커져서 (30개 이상) 자유도가 증가하면 표준정규분포와 거의 같은 분포가 된다.
              - 데이터가 연속형일 경우 활용한다.
              - **두 집단의 평균이 동일한지** 알고자 할 때 검정통계량으로 활용된다.
              - ![t-distribution](https://user-images.githubusercontent.com/291782/161783614-810d0d10-ffe0-483c-99c2-93a7f7159e2f.png)

          - X<sup>2</sup>-분포 (chi-square distribution, 카이제곱분포)

              - 모평균과 모분산이 알려지지 않은 모집단의 모분산에 대한 가설 검정에 사용되는 분포
              - **두 집단 간의 동질성 검정에 활용**된다. (범주형 자료에 대해 얻어진 관측값과 기대값의 차이를 보는 적합성 검정에 활용)
              - ![x2-distribution](https://user-images.githubusercontent.com/291782/161784229-f6906799-74d1-4fd5-a6c6-06bcf9cadaaa.png)

          - F-분포 (F-distribution)

              - **두 집단간 분산의 동일성 검정**에 사용되는 검정 통계량 분포
              - 확률변수는 항상 양의 값만을 갖고 X<sup>2</sup> 분포와 달리 자유도를 2개 가지고 있으며 자유도가 커질수록 정규분포에 가까워진다.
              - ![f-distribution](https://user-images.githubusercontent.com/291782/161784584-b404679b-b455-40d9-91f8-1ffbb0589f98.png)

              



#### 5. 추정과 가설검정 (p.293)

##### 가. 추정의 개요

1.   확률표본 (random sample)
     -   확률분포는 분포를 결정하는 평균, 분산 등의 모수(parameter)를 가지고 있다.
     -   특정한 확률분포로부터 독립적으로 반복해 표본을 추출하는 것이다.
     -   각 관찰값들은 서로 독립적이며 동일한 분포를 갖는다.
2.   추정
     -   표본으로부터 미지의 모수를 추측하는 것이다.
     -   추정은 점추정 (point estimation)과 구간추정(interval estimation)으로 구분된다.
     -   점추정 (point estimation)
         -   '**모수가 특정한 값일 것**'이라고 추정하는 것이다.
         -   표본의 평균, 중위수, 최빈값 등을 사용한다.
         -   불편성 (unbiasedness) : 표본에서 얻는 추정량의 **기댓값**은 모집단의 모수와 차이가 없다.
         -   효율성 (efficiency) : 추정량의 분산이 작을수록 좋다.
         -   일치성 (consistency) : 표본의 크기가 아주 커지면, 추정량이 모수와 거의 같아진다.
         -   충족성 (sufficient) : 추정량은 모수에 대하여 모든 정보를 제공한다.
         -   표본평균 (sample mean) : 모집단의 평균(모평균)을 추정하기 위한 추정량. 확률표본의 평균값.
         -   $\overline{X} = \dfrac {1}{n}\displaystyle \sum_{i=1}^{n}X_i$
         -   표본분산 (sample variance) : 모집단의 분산 (모분산)을 추정하기 위한 추정량
         -   $S^2 = \dfrac {1}{n-1} \displaystyle \sum_{i=1}^{n} (X_i - \overline{X})^2$
     -   구간추정 (interval estimation)
         -   **모수가 특정한 구간에 있을 것이라고 선언하는 것**이다.
         -   항상 추정량의 분포에 대한 전제가 주어져야 하고, 구해진 구간 안에 모수가 있을 가능성의 크기 (신뢰수준(confidence interval))가 주어져야 한다.
         -   95% 신뢰수준 하에서 모평균의 신뢰구간 (모분산을 알때는 분자에 &sigma;(시그마)를 넣고, 모분산을 모를땐 분자에 s를 넣는다.)
         -   모분산 &sigma;<sup>2</sup> 이 알려져 있는 경우
         -   $(\overline{X} - 1.96 \dfrac {\sigma}{\sqrt{n}}, \overline{X} + 1.96 \dfrac {\sigma}{\sqrt{n}})$ , 표준정규분포 N(0, 1)를 따르는 $Z = \dfrac {\overline{X} - \mu} {\dfrac {\sigma} {\sqrt{n}}}$
         -   모분산 &sigma;<sup>2</sup> 이 알려져 있지 않은 경우에는 모분산 대신 표본분산을 사용
         -   $(\overline{X} - 2.26 \dfrac {S}{\sqrt{n}}, \overline{X} + 2.26 \dfrac {S}{\sqrt{n}})$ , 자유도가 n-1인 t-분포를 따르는 $T = \dfrac {\overline{X} - \mu} {\dfrac {S} {\sqrt{n}}}$



##### 나. 가설검정

-   귀무가설 (null hypothesis, H<sub>0</sub>) : **비교하는 값과 차이가 없다, 동일하다**를 기본개념으로 하는 가설
-   대립가설 (alternative hypothesis, H<sub>1</sub>) : **뚜렷한 증거가 있을 때 주장하는 가설**
-   검정통계량 (test statistic) : 관찰된 표본으로부터 구하는 통계량, 검정 시 가설의 진위를 판단하는 기준
-   **유의수준** (significance level, &alpha;) : 귀무가설을 기각하게 되는 확률의 크기로 '귀무가설이 옳은데도 이를 기각하는 확률의 크기'
-   기각역 (critical region, C) : 귀무가설이 옳다는 전제하에서 구한 검정통계량의 분포에서 확률이 유의수준 &alpha;인 부분 (반대는 채택역 (acceptance region))
-   ![hypothesis](https://user-images.githubusercontent.com/291782/161790640-44316c2d-58db-4eb9-94e8-182c00887aa5.png)
-   ![alpha-beta](https://user-images.githubusercontent.com/291782/161790831-f7bb96a8-8f59-4a83-b303-0b85d53a9c76.png)





#### 6. 비모수 검정 (p.296)

모집단의 모수에 대한 검정은 **모수적 검정**과 **비모수적 검정**으로 구분한다.

##### 가. 모수적 방법

-   모집단의 분포에 대한 가정을 하고, 그 가정하에서 검정통계량과 검정통계량의 분포를 유도해 검정을 실시하는 방법

##### 나. 비모수적 방법

-   자료가 추출된 **모집단의 분포에 대한 아무 제약을 가하지 않고 검정을 실시**하는 방법
-   관측된 자료가 특정 분포를 따른다고 가정할 수 없는 경우에 이용
-   관측된 **자료의 수가 많지 않거나** (30개 미만), 자료가 개체간의 **서열관계를 나타내는 경우**에 이용

##### 다. 모수적 검정과 비모수적검정의 차이점

1.   가설의 설정
     -   모수적 검정 : 가정된 모수의 분포에 대해 가설을 설정
     -   비모수적 검정 : 가정된 분포가 없으므로 가설은 단지 '분포의 형태가 동일하다' 또는 '분포의 형태가 동일하지 않다'와 같이 **분포의 형태에 대해 설정**한다.
2.   검정 방법
     -   모수적 검정 : 관측된 자료를 이용해 구한 **표본평균, 표본분산** 등을 이용해 검정을 실시
     -   비모수적 검정 : 절대적인 크기에 의존하지 않고 **관측값들의 순위**(rank)나 **두 관측값 차이의 부호** 등을 이용해 검정

##### 라. 비모수 검정의 예

-   부호검정 (sign test), 윌콕슨의 순위합검정 (rank sum test), 윌콕슨의 부호순위합검정 (Wilcoxon signed rank test), 만-위트니의 U 검정, 런검정 (run test), 스피어만의 순위상관계수





### 2절 기초 통계분석

#### 1. 기술통계 (Descriptive Statistics) (p.298)
##### 가. 기술통계의 정의

- 자료의 특성을 표, 그림, 통계량 등을 사용하여 쉽게 파악할 수 있도록 정리/요약하는 것
- 대략저인 통계적 수치를 계산해봄으로써 데이터에 대한 대략적인 이해와 앞으로 분석에 대한 통찰력을 얻기 유리



##### 나. 통계량에 의한 자료 정리

1. 중심위치의 측도
   - 표본평균 (sample mean) : $\overline{X} = \dfrac {1}{n}(X_1 + X_2 + ... X_n) = \displaystyle \sum_{i=1}^{n} \dfrac{X_i}{n}$
   - 중앙값 (median) : 크기순으로 나열 시 중앙에 위치하는 값
     - n이 홀수인 경우 : $\dfrac {(n+1)}{2}$
     - n이 짝수인 경우 : $\dfrac {n}{2}$ 번째 값과 $\dfrac {(n+1)}{2} + 1$번째 값의 평균
2. 산포의 측도
   - 대표적인 산포도 (dispersion)는 분산, 표준편차, 범위 및 사분위수범위
   - 분산 : $S^2 = \dfrac {1}{n-1} \displaystyle \sum_{i=1}^{n}(X_i - \overline{X})^2 = \dfrac {1}{n-1}(\displaystyle \sum_{i=1}^{n}X_i^2 - n\overline{X}^2) $
   - 표준편차 : $S = \sqrt{S^2} = \sqrt{\dfrac {1}{n-1} \displaystyle \sum_{i=1}^{n} (X_i - \overline{X})^2}$
   - 사분위수범위 (interquartile range) : IQR = Q3 - Q1
   - 사분위수 : Q1 (25백분위수), Q2 (50백분위수), Q3 (75백분위수)
   - 백분위수 (percentile) : $\dfrac {(n-1)p} {100 + 1}$번째 값
   - 변동계수 (coefficient of variation) : $V = \dfrac {S} {\overline{X}}$
   - 평균의 표준오차 : $SE(X) = \dfrac {S} {\sqrt{n}}$
   - ![percentile-iqr](https://user-images.githubusercontent.com/291782/162159496-84d2c7a6-f413-4748-ba66-ea6d5a62c71b.png)
3. 분포의 형태에 관한 측도
   - 왜도 (skewness) :분포의 비대칭정도를 나타내는 측도. 왜도가 양수인 경우 왼쪽에 밀집되어 있고, 오른쪽으로 긴 꼬리를 갖는 분포, 음수인 경우는 반대. 왜도가 0 일 경우는 좌우 대칭인 분포
     - ![skewness](https://user-images.githubusercontent.com/291782/162161124-9884c740-21f4-42f1-898f-997cfa30063e.png)
   - 첨도 (kurtosis) : 분포의 중심에서 뾰족한 정도를 나타내는 측도
     - ![kurtosis](https://user-images.githubusercontent.com/291782/162162023-a35083f7-7fbf-4389-9e61-7a552528df08.png)



##### 다. 그래프를 이용한 자료 정리

1. 히스토그램 : 도수분포표를 그래프로 나타낸 것
2. 막대그래프와 히스토그램의 비교
   - 막대그래프 : **범주형 (category)**으로 구분된 데이터 (예. 직업, 종교, 음식)를 표시하며 범주의 순서를 의도에 따라 바꿀수 있다.
   - 히스토그램 : **연속형(continuous)**으로 표시된 데이터 (키, 몸무게, 성적, 연봉)을 표현하며 임의의 순서를 바꿀수 없고 막대의 간격이 없다.



#### 2. 인과관계의 이해 (p.303)
##### 가. 용어

-   종속변수 (반응변수, y) : 다른 변수의 영향을 받는 변수
-   독립변수 (설명변수, x) : 영향을 주는 변수
-   산점도에서 확인할 사항
    -   두 변수 사이의 선형관계(직선관계)가 성립하는가?
    -   두 변수 사이의 함수관계(직선관계 또는 곡선관계)가 성립하는가?
    -   이상값이 존재하는가?
    -   몇 개의 집단으로 구분(층별)되는 가?



##### 나. 공분산 (covariance)

-   두 확률변수 X, Y의 방향성의 조합(선형성)이다.
-   공분산의 부호가 + 이면 양의 방향성, - 이면 음의 방향성을 가짐
-   X, Y가 서로 독립이면 $Cov (X, Y) = 0$ 이다.



#### 3. 상관분석 (Correlation Analysis)

##### 가. 상관분석 정의

-   두 변수의 상관관계를 알아보기 위해 상관계수 (correlation coefficient)를 이용하며, 그 공식은 아래와 같다.
-   $r = \dfrac {cov(x, y)} {S_x ⅹ S_y} = \dfrac {\displaystyle \sum_{i=1}^n [(x - \overline{x})(y - \overline{y})]} {n(S_x ⅹ S_y)}$



##### 나. 상관관계의 특성

-   $0.7 \lt  r \le 1$ : 강한 양(+)의 상관관계, $0 \lt  r \le 0.3$ : 거의 상관 음다. ,r = 0 : 상관관계(선형, 직선)가 없다.
-   $-1 \le  r \lt 0.7$ : 강한 음(-)의 상관관계, $-0.7 \le  r \lt 0.3$ : 약한 음(-)의 상관관계



##### 다. 상관분석의 유형

|   구분   | 피어슨                                                  | 스피어만                                                  |
| :------: | ------------------------------------------------------- | --------------------------------------------------------- |
|   개념   | 등간척도 이상으로 측정된 두 변수들의 상관관계 측정 방식 | 서열척도인 두 변수들의 상관관계 측정 방식                 |
|   특징   | 연속형 변수, 정규성 가정, 대부분 많이 사용              | 순서형 변수, 비모수적 방법, 순위를 기준으로 상관관계 측정 |
| 상관계수 | 피어슨 $r$ (적률상관계수)                               | 순위상관계수 $(p, 로우)$                                  |

>   피어슨 스피어만 구분 Tip : 스피어만, 서열척도, 순서, 순위상관계수 등의 단어는 모두 "ㅅ" 으로 시작



##### 라. 상관분석을 위한 R코드

```R
# 분산
var(x,y = NULL, na.rm = FALSE)

# 공분산
cov(x,y = NULL, use="everything",
   method = c("pearson", "kendall", "spearman"))

# 상관관계
cor(x,y = NULL, use = "everything",
   method = c("pearsono", "kendall", "spearman"))
# 상관관계 Hmisc 패키지의 rcorr 사용
rcorr(matrix(data명), type=c("pearson", "kendall", "spearman"))
```



##### 마. 상관분석의 가설 검정

-   상관계수 $r$이 0이면 입력변수 x와 출력변수 y 사이에는 아무런 관계가 없다. (귀무가설: $r = 0$, 대립가설 $r\neq 0$)
-   t 검정통계량을 통해 얻은 p-value 값이 0.05이하인 경우, 대립가설을 채택하게 되어 우리가 구한 상관계수를 활용할 수 있게 됨



##### 바. 상관분석 예제

mtcars 데이터셋의 마일(mpg), 총마력(hp)의 상관관계 분석

```R
> data("mtcars")
> a <- mtcars$mpg
> b <- mtcars$hp
> cov(a, b)
[1] -320.7321
> cor(a, b)
[1] -0.7761684
> cor.test(a, b, method="pearson")

	Pearsons product-moment correlation

data:  a and b
t = -6.7424, df = 30, p-value = 1.788e-07
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 -0.8852686 -0.5860994
sample estimates:
       cor 
-0.7761684 
```

-   분석결과 : 공분산 (covariance)은 -320.73, 상관계수 (correlation coefficient)는 -0.776
-   따라서 mpg와 hp는 음의 방향성을 가지며, 상관계수로 강한 음의 상관관계가 있음을 알 수 있음
-   cor.test를 이용해 나온 p-value 가 1.788e-07로 유의수준 0.05보다 작게 나타나므로 mpg와 hp가 상관관계가 있다고 할 수 있다.



### 3절 회귀분석 (중요. 3 ~ 5문제)

#### 1. 회귀분석의 개요 (p.309)

##### 가. 회귀분석 정의

- 하나나 그 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계기법
- 변수들 사이의 인과관계를 밝히고 모형을 적합하여 관심있는 변수를 예측하거나 추론하기 위한 분석방법
- 독립변수 개수가 하나이면 단순선형회귀분석, 독립변수가 두 개 이상이면 다중선형회귀분석으로 분석 할 수 있다.



##### 나. 회귀분석의 변수

- 영향을 받는 변수 (y) : 반응변수 (response variable), 종속변수 (dependent variable), 결과변수 (outcome variable)
- 영향을 주는 변수 (x) : 설명변수 (explanatory variable), 독립변수 (independent variable), 예측변수 (predicator variable)



##### 다. 선형회귀분석의 가정

- **선형성** : 입력변수와 출력변수의 관계가 선형이다
- 등분산성 : 오차의 분산이 입력변수와 무관하게 일정하다.
- 독립성 : 입력변수와 오차는 관련이 없다. 독립성을 알아보기 위해 Dubrin-Watson 통계량 사용. 주로 시계열 데이터에서 많이 활용
- 비상관성 : 오차들끼리 상관이 없다.
- 정상성 (정규성) : 오차의 분포가 정규분포를 따른다. Q-Q plot, Kolmogolov-Smirnov 검정, Shaprio-Wilk 검정 등을 활용하여 정규성을 확인



##### 라. 그래프를 활용한 선형회귀분석의 가정 검토

| 선형성                                                       | 등분산성                                                     | 정규성                                                       |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------------------------------------ |
| ![linear](https://user-images.githubusercontent.com/291782/162400779-89b3cc2b-e948-4f2e-a217-8251396f5225.png) | ![residuals](https://user-images.githubusercontent.com/291782/162400366-c11a9068-d55f-4f77-aebb-3432abe8678f.png) | ![normal-qqplot](https://user-images.githubusercontent.com/291782/162400224-35785847-68a1-4025-8ac9-8b9dca8fc9f0.png) |



##### 마. 가정에 대한 검증

- 단순선형회귀분석 : 입력변수와 출력변수간 선형성을 점검하기 위해 산점도를 확인
- 다중선형회귀분석 : 선형회귀분석의 가정인 선형성, 등분산성, 독립성, 정상성이 모두 만족하는지 확인



#### 2. 단순선형회귀분석 (p.311)

- 독립변수가 종속변수에 미치는 영향을 추정하는 통계 기법
- ![linear-regression](https://user-images.githubusercontent.com/291782/162449647-a02d3869-0d0b-4c51-a083-90a63717c624.png)



##### 가. 회귀분석에서의 검토사항

-   회귀계수들이 유의미한가? 
    -   해당 계수의 t 통계량의 p-value 가 0.05보다 작으면 해당 회귀계수가 통계적으로 유의미하다고 볼 수 있다.
-   모형이 얼마나 설명력을 갖는가?
    -   결정계수(R<sup>2</sup>)를 확인한다. 결정계수는 0 ~ 1 값을 가지며, 높은 값을 가질수록 추정된 회귀식의 설명력이 높다.
-   모형이 데이터를 잘 적합하고 있는가?
    -   잔차를 그래프로 그리고 회귀진단을 한다.



##### 나. 회귀계수의 추정 (최소제곱법, 최소자승법)



##### 다. 회귀분석의 검정

1.   회귀계수의 검정

-   10년간의 에어컨 예약대수와 판매대수 (단위: 1,000대)

| 예약대수(X) | 19   | 23   | 26   | 29   | 30   | 38   | 39   | 46   | 49   |
| ----------- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- | ---- |
| 판매대수(Y) | 33   | 51   | 40   | 49   | 50   | 69   | 70   | 64   | 89   |

위 데이터에 대한 단순회귀분석을 실시

```R
> x <- c(19, 23, 26, 29, 30, 38, 39, 46, 49)
> y <- c(33, 51, 40, 49, 50, 69, 70, 64, 89)
> lm(y~x) # linear regression

Call:
lm(formula = y ~ x)

Coefficients:
(Intercept)            x  
      6.409        1.529  

> summary (lm(y~x))

Call:
lm(formula = y ~ x)

Residuals:
    Min      1Q  Median      3Q     Max 
-12.766  -2.470  -1.764   4.470   9.412 

Coefficients:
            Estimate Std. Error t value Pr(>|t|)    
(Intercept)   6.4095     8.9272   0.718 0.496033    
x             1.5295     0.2578   5.932 0.000581 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1

Residual standard error: 7.542 on 7 degrees of freedom
Multiple R-squared:  0.8341,	Adjusted R-squared:  0.8104 
F-statistic: 35.19 on 1 and 7 DF,  p-value: 0.0005805
```

-   X의 회귀계수인 t 통계량에 대한 p-value 가 0.0005805로 나타나, 유의수준 0.05보다 작으므로 회귀계수의 추정치들이 통계적으로 유의함
-   결정계수 (R<sup>2</sup>) 0.8341로 높게 나타나 회귀식이 데이터를 적절하게 설명하고 있다 할 수 있음
-   회귀분석 결과 "판매대수 = 6.409 + 1.529 * 예약대수"의 회귀식을 구할 수 있다.



2.   결정계수

![r2](https://user-images.githubusercontent.com/291782/162452511-f3bca308-98f2-4dd9-a7d4-fffad044fe47.png)

-   전체제곱합 (total sum of squares, SST) : $\displaystyle \sum_{i=1}^n(y_i - \overline{y})^2$
-   회귀제곱합 (regression sum of squares, SSR) : $\displaystyle \sum_{i=1}^n(\hat{y}_i - \overline{y})^2$
-   오차제곱합 (error sum of squares, SSE) : $\displaystyle \sum_{i=1}^n(y_i - \hat{y})^2$
-   결정계수 (R<sup>2</sup>)는 전제제곱합 (SST)에서 회귀제곱합 (SSR)의 비율 (SSR / SST), 0 &le; R<sup>2</sup> &le; 1 (SST = SSR + SSE)



3.   회귀직선의 적합도 검토

     -   R2는 독립변수가 종속변수의 변동을 몇 %를 설명하는지 나타내는 지표
     -   다변량 회귀분석에서는 독립변수의 수가 많아지면 R2 가 높아지므로 독립변수가 유의하든 않든 R2가 높아지는 단점이 있음
     -   위 단점을 보완하기 위해 수정 결정계수 (R<sub>a</sub><sup>2</sup>: adjusted R<sup>2</sup>)를 활용한다. 수정결정 계수는 결졍계수보다 작은 값으로 산출되는 특징
     -   수정결정계수 : $1 - \dfrac {(n-1)(1 - R^2)}{n - k - 1} = 1 - \dfrac {(n-1) Ⅹ (\dfrac {SSE} {SST})} {n - k - 1} = 1 - (n - 1) \dfrac {MSE} {SST}$
     -   (k: 독립변수 개수, n : 데이터의 개수)
     -   오차(error) : 모집단에서 실제값이 회귀선과 비교해 볼 때 나타나는 차이 (정확치와 관측지의 차이)
     -   잔차 (residual) : 표본에서 나온 관측값이 회귀선과 비교해볼 때 나타나는 차이

     

     

     #### 3. 다중선형회귀분석 (p.315)

     ##### 가. 다중선형회귀분석 (다변량회귀분석)

     -   다중회귀식 : $Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon$

     -   모형의 통계적 유의성

         -   모형의 통계적 유의성은 F-통계량으로 확인

         -   유의수준 5% 하에서 F-통계량의 p-value가 0.05보다 작으면 통계적으로 유의함

         -   F-통계량이 크면 p-value가 0.05보다 작아지고 이렇게 되면 귀무가설을 기각한다.

             >   귀무가설 : $H_0: \beta_1 = \beta_2 = ... \beta_k = 0$ vs 대립가설 : $H_1 : \beta_1 \neq \beta_2 \neq ... \neq \beta_k \neq 0$

             | 요인 |      제곱합      | 자유도 |      제곱평균       |   F-통계량    |
             | :--: | :--------------: | :----: | :-----------------: | :-----------: |
             | 회귀 | 회귀제곱합(SSR)  |   k    |    MSR = SSR / k    | F = MSR / MSE |
             | 오차 | 오차제곱합(SSE)  | n-k-1  | MSE = SSE / (n-k-1) |               |
             |  계  | 전체제곱합 (SST) |  n-1   |                     |               |

         -   모형의 설명력은 결정계수(R<sup>2</sup>)나 수정결정계수(R<sub>a</sub><sup>2</sup>)를 확인
         -   모형의 적합성 : 잔차와 종속변수의 산점도로 확인
         -   데이터가 전제하는 가정을 만족하는가? 선형성, 독립성, 등분산성, 비상관성, 정상성
         -   다중공선성 (multicollinearity)
             -   다중회귀분석에서 설명변수들 사이에 선형관계가 존재하면 회귀계수의 정확한 추정이 곤란
             -   다중공선성 검사방법
                 -   분산팽창요인 (VIF) : 4보다 크면 다중공선성이 존재, 10보다 크면 심각한 문제가 있는것으로 해석
                 -   상태지수 : 10이상이면 문제가 있음, 30보다 크면 심각한 문제가 있음

     

3.   #### 4. 회귀분석의 종류 (p.316)

     -   단순회귀 : $Y = \beta_0 + \beta_1X + \epsilon$ : 독립변수가 1개이며 종속변수와의 관계가 직선
     -   다중회귀 : $Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + ... + \beta_kX_k + \epsilon $ : 독립변수가 k개 이며 종속변수와의 관계가 선형 (1차함수)
     -   로지스틱회귀 : $P(y) = \dfrac {1} {1 + exp[-(\beta_0 + \beta_1X_1 + ... + \beta_kX_k + \epsilon)]}$  : 종속변수가 범주형(2진변수)인 경우에 적용되며, 단순 로지스틱 회귀 및 다중, 다항 로지스틱 회귀로 확장될 수 있음
     -   다항회귀 : K=2이고 2차 함수인 경우
         -   $Y = \beta_0 + \beta_1X_1 + \beta_2X_2 + \beta_{11}X_1^2 + \beta_{22}X_2^2 + \beta_{12}X_1X_2 + \epsilon$ 
         -   독립변수와 종속변수와의 관계가 1차함수 이상인 관계 (단, k=1이면 2차 함수 이상)
     -   곡선회귀
         -   2차 곡선인 경우 : $Y = \beta_0 + \beta_1X + \beta_2X^2 + \epsilon $
         -   3차 곡선인 경우 : $Y = \beta_0 + \beta_1X + \beta_2X^2 + \beta_3X^3 + \epsilon $
         -   독립변수가 1개이며 종속변수와의 관계가 곡선
     -   비선형회귀 : $Y = \alpha e^{-\beta X} + \epsilon $ : 회귀식의 모양이 미지의 모수들의 선형관계로 이뤄져 있지 않은 모형



#### 5. 회귀분석 사례 (p.316)



#### 6. 최적회귀방정식 (p.319)

-   읽었는데 잘 이해가 안됨
-   ==F-Value, T-value, AIC, BIC 다시 공부해라 (중요)==
-   



### 4절 시계열 분석

#### 1. 시계열 자료 (p.328)


     











## ADsP 데이터 분석 END

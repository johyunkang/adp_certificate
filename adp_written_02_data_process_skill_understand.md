## 2과목 데이터 처리 기술 이해 (10)

### 1장 데이터 처리 프로세스

### 1절 ETL (Extraction, Transformation and Load)

#### 1. ETL 개요 (p.196)

##### 가. ETL의 개념 및 특징

-   ETL은 **데이터의 이동 및 변환** 절차와 관련된 업계 표준 용어이다.

-   데이터 원천으로 부터 데이터를 추출 및 변환하여 운영 데이터 스토어 (ODS, Operational Data Store), 데이터 웨어 하우스(DW), 데이터 마트(DM) 등에 데이터를 적재하는 작업의 핵심 구성요소이다.

-   대용량 데이터를 처리하기 위한 MPP (Massively Parallel Processing)을 지원할 수 있다.

-   ETL 구현을 위한 여러 상용 소프트웨어 들이 있으며, Batch(일괄) ETL, Real Time (실시간) ETL로 구분된다.

    >   MPP (Massively Parallel Processing): 프로그램을 여러 부분으로 나누어 여러 프로세스가 각 부분을 동시에 수행시키는 것으로 대규모 병렬 처리를 의미한다.

##### 나. ETL의 기능

-   Extraction (추출) : 하나 또는 그 이상의 데이터 원천(Source)들로 부터 데이터 획득
-   Transformation (변형): 데이터 클렌징. 형식변환. 표준화, 통합 또는 다수 애플리케이션에 내장된 비즈니스 룰 적용 등
-   Load (적재) : 변형 단계의 처리가 완료된 데이터를 특정 목표 시스템에 적재

##### 다. ETL의 작업 단계

1.   Step 0 interface : 다양한 이기종 DBMS 및 스프레드시트 등 데이터 원천(source)으로부터 데이터를 획득하기 위한 인터페이스 메커니즘 구현
2.   Step 1 Staging ETL : 수립된 일정에 따라 데이터 원천(Source)으로부터 트랜잭션 데이터 획득 작업 수행 후, 획득된 데이터를 스테이징 테이블에 저장
3.   Step 2 Profilling ETL : 스테이징 테이블에서 데이터 특성을 식별하고 품질을 측정
4.   Step 3 Cleansing ETL : 다양한 규칙득을 활용해 프로파일링된 데이터의 보정 작업을 수행
5.   Step 4 Integration ETL : (이름, 값, 구조) 데이터 충돌을 해소하고, 클렌징된 데이터를 통합
6.   Step 5 Denormalizing ETL : 운영 보고서 생성 및 데이터 웨어하우스 또는 데이터 마트에 대한 데이터 적재를 위해 데이터 비정규화 수행



#### 2. ODS 구성 (p.198)

##### 가. ODS의 개념 및 특징

-   ODS (Operation Data Store)는 데이터에 대한 추가 작업을 위해 다양한 데이터 원천(Source)들로부터 데이터를 추출.통합한 데이터베이스다.
-   ODS 내의 데이터는 향후 비즈니스 지원을 위해 타 정보시스템으로 이관되거나, 다양한 보고서 생성을 위해 데이터 웨어하우스로 이관된다.
-   ODS를 위한 데이터 통합은 일반적으로 데이터 클렌징, 중복제거, 비즈니스 룰 대비 데이터 무결성 점검 등의 작업들을 포함한다.
-   실시간(Real Time) 또는 실시간 근접(Near Real Time) 트랜잭션 데이터 혹은 가격 등의 원자성(개별성)을 지닌 하위 수준 데이터들을 저장하기 위해 설계된다.

##### 나. ODS 구성 단계

-   ODS 구성을 위한 일괄 작업 ETL은 아래와 같은 단계(Layer)로 구성될 수 있으며, 각 단계에 대한 설명은 아래와 같다.

![layerd ODS Architecture](https://user-images.githubusercontent.com/291782/155846729-4c6e88f6-6e48-442d-a1d1-ad35aefe9359.png)

1.   인터페이스 단계
     -   다양한 데이터 원천으로부터 데이터를 획득하는 단계
     -   프로토콜로는 OLEDB (Object Linking and Embedding DB), ODBC (Object Data Base Connectivity), FTP (File Transfer Protocol) 등이 사용된다.
     -   DW에 대한 실시간(Real TIme) 또는 근접 실시간 OLAP (On-Line Analytical Processing) 질의를 지원하기 위해 실시간 데이터 복제 인터페이스 기술들이 함께 활용된다.
2.   데이터 스테이징 단계
     -   트랜잭션 데이터들이 추출되어 하나 또는 그 이상의 **스테이징 테이블들에 저장**되는 단계이다.
     -   이 테이블들은 정규화가 배제되며, 테이블의 스키마는 데이터 원천의 구조에 의존적이다.
     -   데이터 원천과 스테이징 테이블과의 데이터 매핑은 **일대일 또는 일대다**로 구성될 수 있다.
     -   스테이징 테이블들에 적재되는 시점에 적재 타임스탬프, 데이터 값에 대한 체크섬 등의 통제(Control) 정보들이 추가된다.
     -   다양한 이기종 데이터 원천으로부터 데이터를 획득해 스테이징 테이블에 적재하며, 이 때 일괄(Batch) 작업 형태인 정기적인 ETL과 실시간 ETL을 혼용할 수 있다.
3.   데이터 프로파일링 단계
     -   범위.도메인.유일성 확보 등의 규칙을 기준으로 **데이터 품질 점검**을 하는 단계이다.
     -   스테이징 테이블의 데이터에 대한 데이터 프로파일링 수행 > 데이터 프로파일링 결과 통계 처리 > 데이터 품질 보고서 생성 및 공유 의 절차를 거친다.
4.   데이터 클렌징 단계
     -   클렌징 ETL 프로세스들로 데이터 프로파일링 단계에서 식별된 오류 데이터들을 수정하는 단계이다.
5.   데이터 인티그레이션 단계
     -   수정 완료한 데이터를 ODS 내의 **단일 통합 테이블에 적재**하는 단계이다.
6.   익스포트 단계
     -   앞 단계에서 통합된 데이터에 대해 익스포트 규칙과 보안 규칙을 반영한 익스포트 ETL 기능을 수행해 익스포트 테이블을 생성한다. 그 후 다양한 DBMS 클라이언트 또는 데이터 마트, 데이터 웨어하우스에 익스포트 테이블을 적재하는 단계이다.
     -   해당 데이터는 OLAP (On-line analytical Processing) 비정형 질의에 활용될 수 있다.



#### 3. 데이터 웨어하우스 (p.202)

